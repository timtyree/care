{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing a Folder of Tip Logs\n",
    "Tim Tyree<br>\n",
    "6.22.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:33:31.075449Z",
     "start_time": "2021-08-13T03:33:27.783011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic calling is: Smart\n"
     ]
    }
   ],
   "source": [
    "from lib.my_initialization import *\n",
    "from lib import *\n",
    "import trackpy, pandas as pd, numpy as np\n",
    "from lib.routines.comp_imsd import *\n",
    "\n",
    "%autocall 1\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# awareness&chill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T22:26:54.961Z"
    }
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:33:35.007826Z",
     "start_time": "2021-08-13T03:33:34.841201Z"
    }
   },
   "outputs": [],
   "source": [
    "darkmode=True\n",
    "if darkmode:\n",
    "    # For darkmode plots\n",
    "    from jupyterthemes import jtplot\n",
    "    jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# particle tracking by nearest neighbors for a folder of tip logs with trajectory unwrapping at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:34:39.231289Z",
     "start_time": "2021-08-13T03:33:58.808999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.100_Vthresh_-40/Log/ic001.32_log.csv\n",
      "number of files in list: 59\n"
     ]
    }
   ],
   "source": [
    "# #find file interactively\n",
    "# print(\"please select a file from within the desired folder.\")\n",
    "input_fn= search_for_file()\n",
    "# # file='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.5/Log/ic001.21_log.csv'\n",
    "# print(file)\n",
    "# # file='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-2/ds_2_param_set_8/Log/ic_200x200.001.12_log.csv'\n",
    "# input_fn=file\n",
    "# ds=10\n",
    "# width=10\n",
    "ds=5\n",
    "width=200\n",
    "height=width\n",
    "DS=ds/width\n",
    "\n",
    "\n",
    "# #token LR local data run \n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/Log/ic001.21_log.csv\"\n",
    "\n",
    "# #token FK local data run \n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_30_diffCoef_0.001_dt_0.025/Log/ic200x200.0.1_log.csv\"\n",
    "# # input_fn=search_for_file()\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_10_diffCoef_0.0005/Log/ic200x200.0.3_traj_sr_400_mem_0.csv\"\n",
    "# df=pd.read_csv(input_fn)\n",
    "# print(input_fn)\n",
    "# DT=compute_DT(df,round_t_to_n_digits=3);print(f\"the time resolution is {DT} ms.\")\n",
    "file=input_fn\n",
    "trgt='log.csv'\n",
    "assert(file[-len(trgt):]==trgt)\n",
    "\n",
    "file_name_list=get_all_files_matching_pattern(file,trgt)\n",
    "print(f\"number of files in list: {len(file_name_list)}\")\n",
    "os.chdir(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:34:45.105214Z",
     "start_time": "2021-08-13T03:34:45.068316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR\n",
      "param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.100_Vthresh_-40\n"
     ]
    }
   ],
   "source": [
    "#works for repositories outside of care\n",
    "# input_fn=file\n",
    "trial_folder_name=os.path.dirname(os.path.dirname(input_fn))\n",
    "ic_suite_fn=os.path.dirname(trial_folder_name)\n",
    "# ic_suite_fn=ic_suite_fn.split('/')[-1]\n",
    "print(ic_suite_fn)\n",
    "trial_folder_name=trial_folder_name.split('/')[-1]\n",
    "print(trial_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:37:17.172256Z",
     "start_time": "2021-08-13T03:37:17.123260Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.025, 200, 'param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.100_Vthresh_-40')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate trajectories, unwrapped trajectories, and mean squared displacements for folder of tip logs\n",
    "npartitions=os.cpu_count()\n",
    "npartitions=2\n",
    "# #particle models\n",
    "# ds=10\n",
    "# width=10\n",
    "# kwargs={\n",
    "#     'input_fn_lst':file_name_list,\n",
    "#     'L':width,\n",
    "#     'DS':ds/width,\n",
    "#     'use_cache_0':True,\n",
    "#     'use_cache_1':True,\n",
    "#     'npartitions':npartitions,\n",
    "#     'sr':3*width,\n",
    "#     'mem':0,\n",
    "#     'trial_folder_name':trial_folder_name,\n",
    "#     'ic_suite_fn':ic_suite_fn\n",
    "# }\n",
    "\n",
    "#full models\n",
    "# ds=5\n",
    "# width=200\n",
    "kwargs={\n",
    "    'input_fn_lst':file_name_list,\n",
    "    'L':width,\n",
    "    'DS':ds/width,\n",
    "    'use_cache_0':True,\n",
    "    'use_cache_1':True,\n",
    "    'npartitions':npartitions,\n",
    "    'sr':3*width,\n",
    "    'mem':0,\n",
    "    'trial_folder_name':trial_folder_name,\n",
    "    'ic_suite_fn':ic_suite_fn\n",
    "}\n",
    "DS,width,trial_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:36:59.037387Z",
     "start_time": "2021-08-13T03:36:59.004543Z"
    }
   },
   "outputs": [],
   "source": [
    "#test the routine that takes log to unwrapped trajectory\n",
    "testing=False\n",
    "if testing:\n",
    "    output_file_name=run_routine_log_to_unwrapped_trajectory(input_fn, use_cache=False,**kwargs)\n",
    "    print(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:37:01.885147Z",
     "start_time": "2021-08-13T03:36:59.841141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:37:29.458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 294347: 2 trajectories present.\n"
     ]
    }
   ],
   "source": [
    "df_summary=workflow_reduce_logs_to_diffcoeff_summary(**kwargs)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T01:57:39.526471Z",
     "start_time": "2021-07-26T01:57:39.494944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function lib.routines.dag_log_to_msd.workflow_reduce_logs_to_diffcoeff_summary(input_fn_lst, L, DS, use_cache_0=True, use_cache_1=False, npartitions=2, **kwargs)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO(later): fix D and Delta_D measurements for functions that compute df_summary\n",
    "workflow_reduce_logs_to_diffcoeff_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# analyze annihilation/creation events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## annihilation events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T16:18:16.781228Z",
     "start_time": "2021-08-06T16:18:04.845521Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/trajectories/ic002.23_traj_sr_600_mem_0.csv\n",
      "the time resolution is 0.025 ms.\n"
     ]
    }
   ],
   "source": [
    "#select a file from trajectories/\n",
    "# input_fn=search_for_file()\n",
    "\n",
    "# # #particle model\n",
    "# # input_fn=\"/Users/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_5/trajectories/pbc_particle_log81_traj_sr_30_mem_0.csv\"\n",
    "# #DONE?: attraction with annihilation and with diffusion\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_5/Log/pbc_particle_log3_log.csv\"\n",
    "# #TODO: attraction with annihilation but without diffusion\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_0_L_10_kappa_1500_varkappa_5/Log/pbc_particle_log1_log.csv\"\n",
    "# ds=10\n",
    "# width=10\n",
    "# pid_col='pid_explicit'\n",
    "\n",
    "\n",
    "# #LR\n",
    "# # # input_fn='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.5/trajectories/ic001.21_traj_sr_600_mem_0.csv'\n",
    "# # # # input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_10_diffCoef_0.0005/Log/ic200x200.0.3_traj_sr_400_mem_0.csv\"\n",
    "input_fn='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/trajectories/ic002.23_traj_sr_600_mem_0.csv'\n",
    "# # input_fn='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/trajectories/ic004.13_traj_sr_600_mem_0.csv'\n",
    "\n",
    "# #FK\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_30_diffCoef_0.001_dt_0.025/trajectories/ic200x200.0.28_traj_sr_600_mem_0.csv\"\n",
    "# # input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_10_diffCoef_0.0005/Log/ic200x200.0.3_traj_sr_400_mem_0.csv\"\n",
    "ds=5\n",
    "width=200\n",
    "pid_col='particle'\n",
    "t_col='t'\n",
    "\n",
    "height=width\n",
    "df=pd.read_csv(input_fn);print(input_fn)\n",
    "DT=np.around(get_DT(df,pid_col=pid_col),5);print(f\"the time resolution is {DT} ms.\")\n",
    "DS=ds/width\n",
    "trial_folder_name=os.path.dirname(os.path.dirname(input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T16:18:17.127854Z",
     "start_time": "2021-08-06T16:18:17.112037Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files in list: 125\n"
     ]
    }
   ],
   "source": [
    "trgt=input_fn[input_fn.find('_traj_'):]\n",
    "# trgt='_traj_sr_600_mem_0.csv'\n",
    "assert(input_fn[-len(trgt):]==trgt)\n",
    "\n",
    "file_name_list=get_all_files_matching_pattern(input_fn,trgt)\n",
    "print(f\"number of files in list: {len(file_name_list)}\")\n",
    "os.chdir(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T16:19:18.856587Z",
     "start_time": "2021-08-06T16:18:17.444537Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termination time was 29999.98 ms\n",
      "printing summary stats on particle lifetimes for one input folder in /home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025:\n",
      "count    51478.000000\n",
      "mean         5.472239\n",
      "std         13.103651\n",
      "min         -0.000000\n",
      "25%          0.100000\n",
      "50%          0.425000\n",
      "75%          2.225000\n",
      "max        231.100000\n",
      "Name: min, dtype: float64\n",
      "\n",
      "Please make a manual decision about minimum_lifetime, crop_start_by, and crop_end_by\n"
     ]
    }
   ],
   "source": [
    "#print summary stats on particle lifetimes for one input folder\n",
    "dft=df.groupby(pid_col)[t_col].describe()\n",
    "df_lifetimes=-dft[['max','min']].T.diff().loc['min']\n",
    "print(f\"termination time was {df[t_col].max():.2f} ms\")\n",
    "\n",
    "print(f\"printing summary stats on particle lifetimes for one input folder in {trial_folder_name}:\")\n",
    "print(df_lifetimes.describe())\n",
    "# print(df_lifetimes.head(10))\n",
    "print(\"\\nPlease make a manual decision about minimum_lifetime, crop_start_by, and crop_end_by\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T02:07:41.129018Z",
     "start_time": "2021-08-04T02:07:41.096176Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:20:59.283605Z",
     "start_time": "2021-08-06T19:20:59.257781Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 200,\n",
       " 'height': 200,\n",
       " 'ds': 5,\n",
       " 'printing': False,\n",
       " 'min_range': 0.5,\n",
       " 'min_duration': 50,\n",
       " 'npartitions': 10,\n",
       " 'filter_beginning': True,\n",
       " 'use_grad_voltage': True,\n",
       " 'use_min_duration': False,\n",
       " 'range_threshold': 0.1,\n",
       " 'round_t_to_n_digits': 5,\n",
       " 'tmin': 100,\n",
       " 'pid_col': 'particle',\n",
       " 't_col': 't',\n",
       " 'max_dur': 149,\n",
       " 'folder_out_name': 'annihilations_mindur_50_maxdur_149_minrange_0.5_rangethresh_0.1'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #particle model\n",
    "min_duration=40  #20. #ms # a pair of particles is considered if their lifetime is at least min_range\n",
    "min_range   =0  #cm  # a pair of particles is considered if their max distance is at least min_range\n",
    "filter_beginning=True\n",
    "use_min_duration=True\n",
    "use_grad_voltage=False\n",
    "range_threshold=10 #cm #filter any deaths occurring at ranges exceeding range_threshold\n",
    "round_t_to_n_digits=5\n",
    "tmin=0.  #filter all times earlier than tmin? i think so?\n",
    "max_dur=0.#ms\n",
    "\n",
    "# #full model fk\n",
    "# min_duration=300##20. #ms\n",
    "# min_range   =.5  #cm\n",
    "# filter_beginning=True\n",
    "# use_min_duration=True\n",
    "# use_grad_voltage=True\n",
    "# range_threshold=.1 #cm #filter any deaths occurring at ranges exceeding range_threshold\n",
    "# tmin=100#ms\n",
    "# max_dur=150#ms #consider no more than the last max_dur milliseconds of either trajectory\n",
    "\n",
    "#full model lr (and fk)\n",
    "min_duration=50##20. #ms\n",
    "min_range   =.5#1.#.2#  #cm #.2 and 1. had 3 events available...\n",
    "filter_beginning=True #i think this does nothing...\n",
    "use_min_duration=False\n",
    "use_grad_voltage=True\n",
    "range_threshold=.1 #cm #filter any deaths occurring at ranges exceeding range_threshold\n",
    "tmin=100#ms\n",
    "max_dur=149#500#ms#150# #consider no more than the last max_dur milliseconds of either trajectory\n",
    "\n",
    "\n",
    "# filter_beginning=False\n",
    "# use_min_duration=False\n",
    "\n",
    "npartitions=os.cpu_count()-2\n",
    "# npartitions=10#1\n",
    "\n",
    "kwargs={\n",
    "    'width':width,\n",
    "    'height':height,\n",
    "    'ds':ds,\n",
    "#     'DT':DT,\n",
    "    'printing':False,\n",
    "    'min_range':min_range,\n",
    "    'min_duration':min_duration,\n",
    "    'npartitions':npartitions,\n",
    "    'filter_beginning':filter_beginning,\n",
    "    'use_grad_voltage':use_grad_voltage,\n",
    "    'use_min_duration':use_min_duration,\n",
    "    'range_threshold':range_threshold,\n",
    "    'round_t_to_n_digits':round_t_to_n_digits,\n",
    "    'tmin':tmin,\n",
    "    'pid_col':pid_col,\n",
    "    't_col':t_col,\n",
    "    'max_dur':max_dur,\n",
    "    'folder_out_name':f'annihilations_mindur_{min_duration}_maxdur_{max_dur}_minrange_{min_range}_rangethresh_{range_threshold}'\n",
    "}#'folder_out_name':f'annihilations\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:21:00.787492Z",
     "start_time": "2021-08-06T19:21:00.767751Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "routine_traj_to_annihilation=get_routine_traj_to_annihilation(**kwargs)\n",
    "def routine(input_fn):\n",
    "    return routine_traj_to_annihilation(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:21:02.007565Z",
     "start_time": "2021-08-06T19:21:01.980110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "use_test=False\n",
    "if use_test:\n",
    "    df=pd.read_csv(routine(input_fn))\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:21:02.438388Z",
     "start_time": "2021-08-06T19:21:02.421251Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO?: test compute_annihilation_events\n",
    "# df_phases=compute_annihilation_events(input_fn,**kwargs)\n",
    "# df_phases.plot(x='tdeath',y='r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:21:02.799203Z",
     "start_time": "2021-08-06T19:21:02.785082Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# #TODO: test whether routine_traj_to_annihilation works\n",
    "# #DONE: copy routine_traj_to_annihilation here\n",
    "# # df_phases = compute_annihilation_events(input_fn, width=width, height=height, ds=ds, pid_col=pid_col, folder_out_name=folder_out_name, **kwargs)\n",
    "# # df_phases = compute_annihilation_events(input_fn, **kwargs)\n",
    "# # from inspect import getsource\n",
    "# # print(getsource(compute_annihilation_events))\n",
    "# fn=f'/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/trajectories/ic002.23_traj_sr_600_mem_0.csv'\n",
    "# df=pd.read_csv(fn)\n",
    "# printing=True\n",
    "# # DT=0.025\n",
    "# # # try:\n",
    "# DT = np.around(get_DT(df, pid_col=pid_col), round_t_to_n_digits)\n",
    "# # # DT = compute_DT(df, round_t_to_n_digits=round_t_to_n_digits)\n",
    "# if printing:\n",
    "#     print(f\"the time resolution is {DT} ms.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:21:03.363489Z",
     "start_time": "2021-08-06T19:21:03.349800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: print how many particles are currently being considered\n",
    "#DONT: plot the distribution of their lifetimes\n",
    "#DONE: consider looking only at particles that are sufficiently long lived\n",
    "#DONE: filter any particles that aren't sufficiently long lived at the start of compute_annihilation_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T02:07:54.652012Z",
     "start_time": "2021-08-04T02:07:54.593798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:21:03.970507Z",
     "start_time": "2021-08-06T19:21:03.929834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # #compute interactions\n",
    "# # df_interactions = compute_df_interactions(input_fn, DS=DS,width=width,height=height,tmin=tmin)\n",
    "# # df_interactions.dropna(inplace=True)\n",
    "# # death_ranges = DS * df_interactions.rT.values\n",
    "# # birth_ranges = DS * df_interactions.r0.values\n",
    "# # df_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:34:45.806205Z",
     "start_time": "2021-08-06T19:21:05.292698Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing features of annihilation events for 125 trajectory .csv files...\n",
      "token example fn: /home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/trajectories/ic014.12_traj_sr_600_mem_0.csv\n",
      "run time for computing features of annihilation events was 819.88 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find all files matching pattern\n",
    "trgt_raw='_traj_'\n",
    "\n",
    "trgt=input_fn[input_fn.find(trgt_raw):]\n",
    "input_fn_lst=get_all_files_matching_pattern(file=input_fn, trgt=trgt)\n",
    "print(f\"computing features of annihilation events for {len(input_fn_lst)} trajectory .csv files...\")\n",
    "print(f\"token example fn: {input_fn_lst[0]}\")\n",
    "#all CPU version\n",
    "b = db.from_sequence(input_fn_lst, npartitions=npartitions).map(routine)\n",
    "start = time.time()\n",
    "retval = list(b)\n",
    "print(f\"run time for computing features of annihilation events was {time.time()-start:.2f} seconds.\")\n",
    "beep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:34:46.186082Z",
     "start_time": "2021-08-06T19:34:46.169609Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_of_files=retval\n",
    "list_of_files=[fn for fn in list_of_files if type(fn)==type(str()) and fn.find('Warning:')==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:34:46.478737Z",
     "start_time": "2021-08-06T19:34:46.465821Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fn=search_for_file()\n",
    "# #full model from unwrapped trajectory\n",
    "# list_of_files=get_all_files_matching_pattern(file=fn,trgt='_annihilations.csv')\n",
    "\n",
    "# print(f\"We're about merge {len(list_of_files)} annihilation .csv files from {trial_folder_name}\")\n",
    "\n",
    "# # list_of_files=input_fn_lst2\n",
    "# # min_range=1#cm\n",
    "# # min_duration=20#ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:34:46.776269Z",
     "start_time": "2021-08-06T19:34:46.762913Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# event_id_int=float(''.join(re.findall(r'-?\\d+\\.?\\d*', fn)))\n",
    "# df['event_id']=event_id_int+(1.+df[pid_col])/(1.+df[pid_col].max()) -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:34:47.313177Z",
     "start_time": "2021-08-06T19:34:47.060297Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging 13 output files to one .csv file...\n",
      "results saved in:\n",
      "/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/annihilations_mindur_50_maxdur_149_minrange_0.5_rangethresh_0.1.csv\n"
     ]
    }
   ],
   "source": [
    "#merge all csv files into one big-ol' csv file\n",
    "print(f\"merging {len(list_of_files)} output files to one .csv file...\")\n",
    "#save_fn=f'annihilations_minr_{min_range}_mindur_{min_duration}.csv'\n",
    "save_fn=kwargs['folder_out_name']+'.csv'\n",
    "file_out=os.path.join(os.path.dirname(os.path.dirname(list_of_files[0])),save_fn)\n",
    "reval=produce_one_csv(list_of_files, file_out)#, encoding=\"utf-8\")\n",
    "print('results saved in:')\n",
    "print(file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T19:34:48.216146Z",
     "start_time": "2021-08-06T19:34:47.592907Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## creation events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T16:01:47.695323Z",
     "start_time": "2021-07-23T16:01:47.678291Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "routine_traj_to_creation=get_routine_traj_to_creation(**kwargs)\n",
    "def routine(input_fn):\n",
    "    return routine_traj_to_creation(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T16:01:48.948555Z",
     "start_time": "2021-07-23T16:01:47.890820Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing features of creation events for 200 trajectory .csv files...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'particle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bd59f45d6c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroutine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"run time for computing features of creation events was {time.time()-start:.2f} seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mbeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/bag/core.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     def groupby(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/multiprocessing.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mpack_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpack_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mraise_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         )\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m                         \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Re-execute locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                         \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/core.py\u001b[0m in \u001b[0;36m_execute_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0margs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mishashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/bag/core.py\u001b[0m in \u001b[0;36mreify\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/bag/core.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2020\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwarg_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnkws\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2022\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_all_iterators_consumed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d2cf3a14a300>\u001b[0m in \u001b[0;36mroutine\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mroutine_traj_to_creation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_routine_traj_to_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mroutine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mroutine_traj_to_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/care/notebooks/lib/measure/compute_topological_events.py\u001b[0m in \u001b[0;36mroutine_traj_to_creation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# retval_ignore= unwrap_trajectories(input_file_name, output_file_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \t\toutput_file_name=save_creation_events(input_file_name,width,height,ds,\n\u001b[0;32m--> 558\u001b[0;31m \t\t\tsave_folder=save_folder,save_fn=save_fn,**kwargs)#,**kwargs)\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutput_file_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mroutine_traj_to_creation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/care/notebooks/lib/measure/compute_topological_events.py\u001b[0m in \u001b[0;36msave_creation_events\u001b[0;34m()\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0msave_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_creation_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,**kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \t'''\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mdf_phases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_creation_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf_phases\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Warning: no creation events considered valid for trial located at \\n\\t {input_fn}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/care/notebooks/lib/measure/compute_topological_events.py\u001b[0m in \u001b[0;36mcompute_creation_events\u001b[0;34m()\u001b[0m\n\u001b[1;32m    425\u001b[0m                         \u001b[0mpid_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid_birthmate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                         \u001b[0;31m#extract d1,d2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                         \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpid_birthmate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                         \u001b[0md1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'particle'"
     ]
    }
   ],
   "source": [
    "#find all files matching pattern\n",
    "trgt_raw='_traj_'\n",
    "trgt=input_fn[input_fn.find(trgt_raw):]\n",
    "input_fn_lst=get_all_files_matching_pattern(file=input_fn, trgt=trgt)\n",
    "print(f\"computing features of creation events for {len(input_fn_lst)} trajectory .csv files...\")\n",
    "\n",
    "#all CPU version\n",
    "b = db.from_sequence(input_fn_lst, npartitions=npartitions).map(routine)\n",
    "start = time.time()\n",
    "retval = list(b)\n",
    "print(f\"run time for computing features of creation events was {time.time()-start:.2f} seconds.\")\n",
    "beep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T16:01:48.987966Z",
     "start_time": "2021-07-23T16:00:47.422Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_of_files=retval\n",
    "list_of_files=[fn for fn in list_of_files if type(fn)==type(str()) and fn.find('Warning:')==-1]\n",
    "# list_of_files=[fn for fn in list_of_files if fn.find('Warning:')==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T16:01:49.008770Z",
     "start_time": "2021-07-23T16:00:47.898Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(list_of_files))\n",
    "assert (len(list_of_files)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T16:01:49.026707Z",
     "start_time": "2021-07-23T16:00:48.513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#merge all csv files into one big-ol' csv file\n",
    "file_out=os.path.join(os.path.dirname(os.path.dirname(list_of_files[0])),f'creations_minr_{min_range}_mindur_{min_duration}.csv')\n",
    "reval=produce_one_csv(list_of_files, file_out)#, encoding=\"utf-8\")\n",
    "print('results saved in:')\n",
    "print(file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T16:01:49.035724Z",
     "start_time": "2021-07-23T16:00:50.262Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSD computation in the bulk of wrapped or unwrapped trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:04:46.147672Z",
     "start_time": "2021-08-13T03:04:44.628652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT=0.025 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>n</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>grad_ux</th>\n",
       "      <th>grad_uy</th>\n",
       "      <th>grad_vx</th>\n",
       "      <th>grad_vy</th>\n",
       "      <th>v</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "      <th>dvdt</th>\n",
       "      <th>dfdt</th>\n",
       "      <th>dsdt</th>\n",
       "      <th>frame</th>\n",
       "      <th>particle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>3.014932</td>\n",
       "      <td>0.974726</td>\n",
       "      <td>-0.302955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.414019</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.844215</td>\n",
       "      <td>-0.029167</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025</td>\n",
       "      <td>22</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>-0.022847</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>2.760992</td>\n",
       "      <td>0.978185</td>\n",
       "      <td>-0.360064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.412141</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.844132</td>\n",
       "      <td>-0.030113</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050</td>\n",
       "      <td>22</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>-0.049944</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>2.545488</td>\n",
       "      <td>0.981200</td>\n",
       "      <td>-0.423354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410013</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.844039</td>\n",
       "      <td>-0.029046</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075</td>\n",
       "      <td>22</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>-0.081613</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>2.353219</td>\n",
       "      <td>0.983940</td>\n",
       "      <td>-0.493241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.407692</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.843934</td>\n",
       "      <td>-0.026276</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>22</td>\n",
       "      <td>0.013569</td>\n",
       "      <td>-0.118039</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>2.177114</td>\n",
       "      <td>0.986472</td>\n",
       "      <td>-0.570140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.405245</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.843817</td>\n",
       "      <td>-0.022053</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t   n         x         y   theta   grad_ux   grad_uy   grad_vx  \\\n",
       "0  0.000  22  0.000000  0.000000 -9999.0  3.014932  0.974726 -0.302955   \n",
       "1  0.025  22  0.002675 -0.022847 -9999.0  2.760992  0.978185 -0.360064   \n",
       "2  0.050  22  0.005492 -0.049944 -9999.0  2.545488  0.981200 -0.423354   \n",
       "3  0.075  22  0.008947 -0.081613 -9999.0  2.353219  0.983940 -0.493241   \n",
       "4  0.100  22  0.013569 -0.118039 -9999.0  2.177114  0.986472 -0.570140   \n",
       "\n",
       "   grad_vy         v         f         s      dvdt      dfdt      dsdt  frame  \\\n",
       "0      1.0  0.414019  0.000815  0.844215 -0.029167 -0.000063 -0.001055      0   \n",
       "1      1.0  0.412141  0.000812  0.844132 -0.030113 -0.000062 -0.001055      1   \n",
       "2      1.0  0.410013  0.000808  0.844039 -0.029046 -0.000062 -0.001055      2   \n",
       "3      1.0  0.407692  0.000804  0.843934 -0.026276 -0.000062 -0.001055      3   \n",
       "4      1.0  0.405245  0.000800  0.843817 -0.022053 -0.000061 -0.001055      4   \n",
       "\n",
       "   particle  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #input_fn is any sort of trajectory .csv file.  it must have a column reffered to by pid_col that uniquely identifies each particle\n",
    "# #Load example particle Log file where I want to compute MSD and tracking has already been done \n",
    "# #(good): data that uses explicit particle tracking\n",
    "# input_fn=search_for_file()\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_0_varkappa_0/Log/pbc_particle_log1_log.csv\"\n",
    "# # input_fn='/Users/timothytyree/Documents/GitHub/care/notebooks/Data/test_data/pbc_particle_log69_log.csv'\n",
    "\n",
    "# #TODO?: no attraction, no annihilation\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_0_varkappa_0/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "#TODO: no attraction with annihilation\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_0/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "#DONE: attraction with annihilation\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_5/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "# #TODO: attraction with annihilation but without diffusion\n",
    "# # input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_0_L_10_kappa_1500_varkappa_5/Log/pbc_particle_log1_log.csv\"\n",
    "# pid_col='pid_explicit'\n",
    "# t_col='t'\n",
    "# width=10 #width of computational domain\n",
    "# ds   =10  #cm\n",
    "\n",
    "\n",
    "#full models\n",
    "#LR\n",
    "# input_fn='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/trajectories/ic002.23_traj_sr_600_mem_0.csv'\n",
    "# # # input_fn='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/trajectories/ic004.13_traj_sr_600_mem_0.csv'\n",
    "# # # input_fn='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.5/trajectories/ic001.21_traj_sr_600_mem_0.csv'\n",
    "# # # input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_10_diffCoef_0.0005/Log/ic200x200.0.3_traj_sr_400_mem_0.csv\"\n",
    "\n",
    "# #unwrapped LR at DT=0.025 ms\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.025/trajectories_unwrap/ic002.11_traj_sr_600_mem_0_unwrap.csv\"\n",
    "\n",
    "# #FK\n",
    "# input_fn\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_10_diffCoef_0.0005/Log/ic200x200.0.3_traj_sr_400_mem_0.csv\"\n",
    "\n",
    "# unwrapped FK at DT=0.025 ms\n",
    "input_fn='/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_30_diffCoef_0.001_dt_0.025/trajectories_unwrap/ic200x200.0.3_traj_sr_600_mem_0_unwrap.csv'\n",
    "\n",
    "# UNCOMMENT HERE FOR FULL MODELS\n",
    "ds=5\n",
    "width=200\n",
    "pid_col='particle'\n",
    "id_col='event_id'\n",
    "t_col='t'\n",
    "\n",
    "trial_folder_name=os.path.dirname(os.path.dirname(input_fn))\n",
    "#(bad)particle data analyzed using full model pipeline\n",
    "# input_fn=\"/Users/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_0/trajectories_unwrap/pbc_particle_log121_traj_sr_30_mem_0_unwrap.csv\"\n",
    "df=pd.read_csv(input_fn)\n",
    "#from here on, we will use units in terms of those used by the full model\n",
    "height=width\n",
    "DS=ds/width\n",
    "DT=np.around(get_DT(df, t_col=t_col, pid_col=pid_col),5);print(f\"DT={DT} ms\")\n",
    "kwargs={}\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T20:05:47.495250Z",
     "start_time": "2021-08-02T20:05:47.473765Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:04:59.430083Z",
     "start_time": "2021-08-13T03:04:59.389685Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "use_unwrap=False\n",
    "#choose use_unwrap=True if the input trajectories are not already unwrapped\n",
    "if use_unwrap:\n",
    "    #unwrap trajectories\n",
    "    pid_lst = sorted(set(df[pid_col].values))\n",
    "    #(duplicates filtered earlier in full model pipeline.  Unnecessary in particle model with explicit tracking_ _  _ _ ) filter_duplicate_trajectory_indices is slow (and can probs be accelerated with a sexy pandas one liner)\n",
    "    # pid_lst_filtered = filter_duplicate_trajectory_indices(pid_lst,df)\n",
    "    #     df = pd.concat([unwrap_traj_and_center(df[df[pid_col]==pid], width, height, DS, **kwargs) for pid in pid_lst])\n",
    "    df = pd.concat([unwrap_traj_and_center(df[df[pid_col]==pid], width, height, **kwargs) for pid in pid_lst])\n",
    "    DT=get_DT(df,pid_col=pid_col) #ms\n",
    "    df[df.frame==2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:05:01.606443Z",
     "start_time": "2021-08-13T03:05:01.312623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing summary stats on particle lifetimes for one input file from /home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_30_diffCoef_0.001_dt_0.025:\n",
      "count      76.000000\n",
      "mean      116.730263\n",
      "std       194.614662\n",
      "min         0.050000\n",
      "25%         3.475000\n",
      "50%        43.550000\n",
      "75%       136.468750\n",
      "max      1017.475000\n",
      "Name: min, dtype: float64\n",
      "\n",
      "Please make a manual decision about minimum_lifetime, crop_start_by, and crop_end_by\n"
     ]
    }
   ],
   "source": [
    "#print summary stats on particle lifetimes for one input folder\n",
    "dft=df.groupby(pid_col)[t_col].describe()\n",
    "df_lifetimes=-dft[['max','min']].T.diff().loc['min']\n",
    "\n",
    "print(f\"printing summary stats on particle lifetimes for one input file from {trial_folder_name}:\")\n",
    "print(df_lifetimes.describe())\n",
    "# print(df_lifetimes.head(10))\n",
    "print(\"\\nPlease make a manual decision about minimum_lifetime, crop_start_by, and crop_end_by\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:05:06.383887Z",
     "start_time": "2021-08-13T03:05:06.352542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'particle'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:05:40.009079Z",
     "start_time": "2021-08-13T03:05:39.965387Z"
    }
   },
   "outputs": [],
   "source": [
    "# # particle models\n",
    "# minimum_lifetime=500. #ms\n",
    "# crop_start_by=150\n",
    "# crop_end_by=150\n",
    "use_particle_avg=True\n",
    "\n",
    "#UNCOMMENT HERE FOR FULL MODELS\n",
    "# #LR model (and FK model)\n",
    "minimum_lifetime=100. #ms\n",
    "crop_start_by=0#40\n",
    "crop_end_by=150#40\n",
    "# use_unwrap=False\n",
    "\n",
    "#(deprecated) #FK model\n",
    "# minimum_lifetime=200. #ms\n",
    "# crop_start_by=40\n",
    "# crop_end_by=40\n",
    "# use_unwrap=False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:05:44.959479Z",
     "start_time": "2021-08-13T03:05:44.927490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT': 0.025,\n",
       " 'ds': 5,\n",
       " 'width': 200,\n",
       " 'minimum_lifetime': 100.0,\n",
       " 'crop_start_by': 0,\n",
       " 'crop_end_by': 150,\n",
       " 'pid_col': 'particle',\n",
       " 't_col': 't',\n",
       " 'max_lagtime': None,\n",
       " 'use_unwrap': False,\n",
       " 'use_particle_avg': True}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# width=10\n",
    "# ds   =10  #cm\n",
    "# pid_col='pid_explicit'\n",
    "# t_col='t'\n",
    "kwargs={\n",
    "    'DT':DT,\n",
    "    'ds':ds,\n",
    "    'width':width,\n",
    "    'minimum_lifetime':minimum_lifetime,\n",
    "    'crop_start_by':crop_start_by,\n",
    "    'crop_end_by':crop_end_by,\n",
    "    'pid_col':pid_col,\n",
    "    't_col':t_col,\n",
    "    'max_lagtime':None,\n",
    "    'use_unwrap':use_unwrap,\n",
    "    'use_particle_avg':use_particle_avg\n",
    "}\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:08:10.978884Z",
     "start_time": "2021-08-13T03:08:09.063998Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of test df_msd:\n",
      "      pid   lagt           msd\n",
      "4421    6  0.000  0.000000e+00\n",
      "4422    6  0.025  3.368236e-08\n",
      "4423    6  0.050  1.424645e-07\n",
      "4424    6  0.075  3.344442e-07\n",
      "4425    6  0.100  6.140708e-07\n",
      "D_naive_estimate=1.3810 cm^2/s\n"
     ]
    }
   ],
   "source": [
    "use_test=True\n",
    "#optionally test the routine\n",
    "#runtime for one file was roughly 40 seconds while sharing with 12 other python processes\n",
    "if use_test:\n",
    "    df_msd=compute_each_mean_squared_displacement(input_fn,**kwargs)\n",
    "#     routine_compute_imsd(input_fn,**kwargs)\n",
    "    print(f\"Head of test df_msd:\")\n",
    "    print(df_msd.head())\n",
    "    #naive estimate for a reasonable diffusion coefficient\n",
    "    D_naive_estimate=1/DT*df_msd[(df_msd['lagt']>0.)&(df_msd['lagt']<1.25*DT)]['msd'].mean()*1000/4\n",
    "    #     D_naive_estimate=DS**2/DT*df_msd[(df_msd['lagt']>0.)&(df_msd['lagt']<1.25*DT)]['msd'].mean()*1000/4\n",
    "    print(f\"D_naive_estimate={D_naive_estimate:.4f} cm^2/s\")    \n",
    "    \n",
    "def routine(input_fn):\n",
    "    try:\n",
    "        return routine_compute_imsd(input_fn,**kwargs)\n",
    "    except Exception as e:\n",
    "        return f\"Warning: something went wrong, {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:07:38.026452Z",
     "start_time": "2021-08-13T03:07:37.971614Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:08:14.650841Z",
     "start_time": "2021-08-13T03:08:14.622380Z"
    }
   },
   "outputs": [],
   "source": [
    "# # compute_each_mean_squared_displacement\n",
    "# lagt_values,msd_values=return_msd_particle_average(input_fn,ds,width,height,use_unwrap,pid_col=pid_col,t_col=t_col,DT=DT)#,**kwargs)\n",
    "# df_msd=pd.DataFrame({'lagt':lagt_values,'msd':msd_values})\n",
    "# plt.plot(lagt_values,msd_values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:08:19.275535Z",
     "start_time": "2021-08-13T03:08:19.238117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_fn=/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_30_diffCoef_0.001_dt_0.025/trajectories_unwrap/ic200x200.0.3_traj_sr_600_mem_0_unwrap.csv\n",
      "We're about to use 12 cores to obliterate 324 trajectory files from /home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_30_diffCoef_0.001_dt_0.025\n"
     ]
    }
   ],
   "source": [
    "#get all files and select number of cores to use\n",
    "npartitions=os.cpu_count()\n",
    "npartitions=12\n",
    "\n",
    "# #particle model from log (wrapped)\n",
    "# trial_folder_name=os.path.dirname(os.path.dirname(input_fn))\n",
    "# input_fn_lst=get_log_files(trial_folder_name, extension='/Log/', trgt='log.csv')\n",
    "# # input_fn_lst=get_log_files(trial_folder_name, extension='', trgt='.csv')\n",
    "\n",
    "#full model from unwrapped trajectory\n",
    "# input_fn_lst=get_all_files_matching_pattern(file=input_fn,trgt='_unwrap.csv')\n",
    "\n",
    "print(f\"input_fn={input_fn}\")\n",
    "input_folder=os.path.dirname(input_fn)\n",
    "os.chdir(input_folder)\n",
    "trgt=input_fn[input_fn.find('_traj_'):]\n",
    "assert(input_fn[-len(trgt):]==trgt)\n",
    "input_fn_lst=get_all_files_matching_pattern(input_fn,trgt)\n",
    "print(f\"We're about to use {npartitions} cores to obliterate {len(input_fn_lst)} trajectory files from {trial_folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:13:20.984374Z",
     "start_time": "2021-08-13T03:08:25.175034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time for computing mean squared displacements was 295.15 seconds.\n",
      "wrote 305 output files to a common folder\n"
     ]
    }
   ],
   "source": [
    "#all CPU version\n",
    "b = db.from_sequence(input_fn_lst, npartitions=npartitions).map(routine)\n",
    "start = time.time()\n",
    "retval = list(b)\n",
    "print(f\"run time for computing mean squared displacements was {time.time()-start:.2f} seconds.\")\n",
    "beep(3)\n",
    "\n",
    "list_of_files=retval\n",
    "list_of_files=[fn for fn in list_of_files if type(fn)==type(str()) and fn.find('Warning:')==-1]\n",
    "# list_of_files=[fn for fn in list_of_files if fn.find('Warning:')==-1]\n",
    "print(f\"wrote {len(list_of_files)} output files to a common folder\")\n",
    "assert (len(list_of_files)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated run time per trial for tavg MSD calculation is 20 seconds.\n",
    "- particle avg: 12 sec per trial*200/12/60 < 5 minutes...\n",
    "\n",
    "Estimated run time per trial for tavg MSD calculation is 20 seconds.\n",
    "- (old ERT: 40 minutes for 200)\n",
    "- new ERT = 200*20/60/12#min\n",
    "\n",
    "- when use_unwrap is false, a whole folder of high-res data from the FK model was computed in about 3 minutes... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:13:21.509806Z",
     "start_time": "2021-08-13T03:13:21.491011Z"
    }
   },
   "outputs": [],
   "source": [
    "# file=list_of_files[2]\n",
    "# pid_col='pid'\n",
    "# # compute_event_id(pd.read_csv(file),input_fn=file,pid_col=pid_col)\n",
    "# df=pd.read_csv(file)\n",
    "# fn = os.path.basename(file)\n",
    "# event_id_int = int(float(100*sum([float(s) for s in re.findall(r'-?\\d+\\.?\\d*', file)])))\n",
    "# df['event_id']=event_id_int+df[pid_col]/df[pid_col].max()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T20:38:58.488007Z",
     "start_time": "2021-08-02T20:38:58.460136Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:26:04.823916Z",
     "start_time": "2021-08-13T03:13:21.807304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged results saved in:\n",
      "/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_30_diffCoef_0.001_dt_0.025/msd_particle_minlifetime_100.0_cropstartby_0_cropendby_150.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge all csv files into one big-ol' csv file\n",
    "basestr='msd_particle'\n",
    "# basestr='msd'\n",
    "file_in=os.path.join(os.path.dirname(os.path.dirname(list_of_files[0])),f'{basestr}_minlifetime_{minimum_lifetime}_cropstartby_{crop_start_by}_cropendby_{crop_end_by}.csv')\n",
    "reval=produce_one_csv(list_of_files, file_in)#, encoding=\"utf-8\")\n",
    "print('merged results saved in:')\n",
    "print(file_in)\n",
    "beep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:27:38.626656Z",
     "start_time": "2021-08-13T03:26:05.139681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>lagt</th>\n",
       "      <th>msd</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200200e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1.200200e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1.200200e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>1.200200e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>1.200200e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid   lagt       msd      event_id\n",
       "0   22  0.000  0.000000  1.200200e+13\n",
       "1   22  0.025  0.000045  1.200200e+13\n",
       "2   22  0.050  0.000242  1.200200e+13\n",
       "3   22  0.075  0.000353  1.200200e+13\n",
       "4   22  0.100  0.000426  1.200200e+13"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load an enormous number of samples into a pandas.DataFrame\n",
    "df_in=pd.read_csv(file_in)\n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:27:48.847433Z",
     "start_time": "2021-08-13T03:27:38.946582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 1 due to unreasonably large msd values...\n"
     ]
    }
   ],
   "source": [
    "#drop all events that have a jump in their first time step...\n",
    "msd_thresh=2\n",
    "df=df_in\n",
    "boo=(df.lagt==DT)&(df.msd>msd_thresh)\n",
    "event_id_drop_lst=sorted(set(df[boo].event_id.values))\n",
    "for event_id in event_id_drop_lst:\n",
    "#     pass\n",
    "    df.drop(index=df[df.event_id==event_id].index,inplace=True)\n",
    "print(f\"dropped {len(event_id_drop_lst)} due to unreasonably large msd values...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:27:49.179284Z",
     "start_time": "2021-08-13T03:27:49.150797Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T03:27:49.509734Z",
     "start_time": "2021-08-13T03:27:49.477370Z"
    }
   },
   "outputs": [],
   "source": [
    "# event_id_values=np.array(sorted(set(df.event_id.values)))\n",
    "# event_id=event_id_values[2]\n",
    "# df[df.event_id==event_id].plot(x='lagt',y='msd')\n",
    "# print(event_id)\n",
    "# plt.show()\n",
    "\n",
    "# #DONE: make a quick histogram of msd values for each event id at a given lagt value\n",
    "# #filter events with unreasonable jumps in msd\n",
    "# # df=df_in\n",
    "# boo=(df.lagt==DT)&(df.msd<=msd_thresh)\n",
    "# # yv=df[boo].msd.values\n",
    "# yv=df.msd.values\n",
    "# plt.hist(yv)\n",
    "# plt.show()\n",
    "\n",
    "# boo=(df.lagt==DT)&(df.msd<=msd_thresh)\n",
    "# yv=df[boo].msd.values\n",
    "# plt.hist(yv)\n",
    "# plt.show()\n",
    "\n",
    "# # from lib.measure.bootstrap import bin_and_bootstrap_xy_values\n",
    "\n",
    "# #TODO(accelerate bin_and_bootstrap_xy_values): parallelize bootstrapping by putting num_bootstrap_samples into a dask bag\n",
    "# #TODO(if control looks reasonable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:08:45.753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 12 cores to bootstrap 120803840 MSD observations from /home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_30_diffCoef_0.001_dt_0.025...\n"
     ]
    }
   ],
   "source": [
    "#extract values\n",
    "lagt_values = df_in['lagt'].values\n",
    "msd_values = df_in['msd'].values\n",
    "print(f\"using {npartitions} cores to bootstrap {msd_values.shape[0]} MSD observations from {trial_folder_name}...\")\n",
    "#bin and bootstrap results\n",
    "bins = 30#'auto'  #\n",
    "dict_out = bin_and_bootstrap_xy_values(x=lagt_values,\n",
    "                                       y=msd_values,\n",
    "                                       xlabel='lagt',\n",
    "                                       ylabel=r'msd',\n",
    "                                       bins=bins,\n",
    "                                       min_numobs=None,\n",
    "                                       num_bootstrap_samples=1000,\n",
    "                                       npartitions=npartitions)\n",
    "df_emsd = pd.DataFrame(dict_out)\n",
    "df_emsd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:08:47.028Z"
    }
   },
   "outputs": [],
   "source": [
    "#save ensemble msd\n",
    "#merge all csv files into one big-ol' csv file\n",
    "file_out=os.path.join(os.path.dirname(os.path.dirname(list_of_files[0])),f'ensemble_{basestr}_bins_{bins}_minlifetime_{minimum_lifetime}_cropstartby_{crop_start_by}_cropendby_{crop_end_by}.csv')\n",
    "df_emsd.to_csv(file_out,index=False)\n",
    "print('merged results saved in:')\n",
    "print(file_out)\n",
    "beep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:12:55.733Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute the linear fit of bootstrapped msd\n",
    "df=df_emsd\n",
    "xscale=0.001 #seconds per ms\n",
    "xmin=10. #ms\n",
    "xmax=2000 #ms\n",
    "xmin*=xscale\n",
    "xmax*=xscale\n",
    "x_values=df['lagt'].values*xscale\n",
    "y_values=df['msd'].values\n",
    "x_err_values=df['Delta_lagt'].values\n",
    "y_err_values=df['Delta_msd'].values\n",
    "counts=df['counts'].values\n",
    "\n",
    "#fit drdt_values to F0+F1/r with OLS fit for LR model where 1/r is greater than some 1/cm\n",
    "boo=(x_values>xmin)&(x_values<xmax)\n",
    "x=x_values[boo]\n",
    "y=y_values[boo]\n",
    "#fix zero\n",
    "def fix_zero(x):\n",
    "    return np.concatenate(([0],x))\n",
    "x=fix_zero(x)\n",
    "y=fix_zero(y)\n",
    "dict_force_fit=compute_95CI_ols(x,y)\n",
    "y_hat_values=dict_force_fit['b']+dict_force_fit['m']*x_values\n",
    "\n",
    "#(optional) rename specific values\n",
    "dict_force_fit=dict_force_fit\n",
    "y_hat_values=y_hat_values\n",
    "\n",
    "#bluf\n",
    "print(f\"D_apparent={dict_force_fit['m']/4:.6f} +- {dict_force_fit['Delta_m']/4:.6f}\")\n",
    "print(f\"the ols fit for diffusion coefficient was computed from {xmin:.3f} to {xmax:.3f} seconds, resulting in D={dict_force_fit['m']/4:.4f} and:\")\n",
    "print_dict(dict_force_fit)\n",
    "print(f\"Nobs= {np.mean(counts):.0f} +- {np.std(counts):.0f}\")\n",
    "print(f\"trial_folder_name: {trial_folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:12:56.533Z"
    }
   },
   "outputs": [],
   "source": [
    "# from lib.measure.measure_diffusion_coefficient import compute_D_OLS_2D\n",
    "# dict_D=compute_D_OLS_2D(lagt_values,msd_values,\n",
    "#                 tmin=300,\n",
    "#                 tmax=3000,\n",
    "#                 tscale=0.001,\n",
    "#                 DS=1)\n",
    "# print(dict_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T02:58:30.022984Z",
     "start_time": "2021-08-13T02:58:29.985663Z"
    }
   },
   "outputs": [],
   "source": [
    "c='C1'#LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T02:58:30.417800Z",
     "start_time": "2021-08-13T02:58:30.385865Z"
    }
   },
   "outputs": [],
   "source": [
    "c='C3'#particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:12:57.113Z"
    }
   },
   "outputs": [],
   "source": [
    "c='C0'#FK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:13:06.128Z"
    }
   },
   "outputs": [],
   "source": [
    "xlim=3#.2#\n",
    "ylim=30#3\n",
    "#plot mean radial velocities\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "\n",
    "lagt_values=df_in['lagt'].values[:10000000:100]\n",
    "msd_values=df_in['msd'].values[:10000000:100]    \n",
    "ax.scatter(lagt_values*xscale,msd_values,alpha=0.008,color='gray',s=1)#,alpha=1,color='k')\n",
    "PlotMeanSquaredDisplacements(ax, x_values, y_values, y_err_values, y_hat_values,c=c)\n",
    "# PlotMeanSquaredDisplacements(ax, fix_zero(x_values), fix_zero(y_values), fix_zero(y_err_values), fix_zero(y_hat_values),c=c)\n",
    "\n",
    "# # plot a known value\n",
    "# xval=(x_values-np.min(x_values))*2\n",
    "# ax.plot(xval,xval*8,'k-')\n",
    "\n",
    "ax.set_xlim([0,xlim])\n",
    "ax.set_ylim([0,ylim])\n",
    "ax.set_xlabel('lag (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:13:07.988Z"
    }
   },
   "outputs": [],
   "source": [
    "ylim=70\n",
    "#plot mean radial velocities\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "\n",
    "# # plot a known value\n",
    "xval=(x_values-np.min(x_values))*2\n",
    "ax.plot(xval,xval*8,'k--')\n",
    "\n",
    "# # lagt_values=df_in['lagt'].values[:1000000:10]\n",
    "# # msd_values=df_in['msd'].values[:1000000:10]    \n",
    "# # ax.scatter(lagt_values*xscale,msd_values,alpha=0.03,color='gray',s=1)#,alpha=1,color='k')\n",
    "# lagt_values=df_in['lagt'].values[:10000000:100]\n",
    "# msd_values=df_in['msd'].values[:10000000:100]    \n",
    "# ax.scatter(lagt_values*xscale,msd_values,alpha=0.08,color='green',s=1)#,alpha=1,color='k')\n",
    "PlotMeanSquaredDisplacements(ax, x_values, y_values, y_err_values, y_hat_values,c=c)\n",
    "\n",
    "# # # plot a known value\n",
    "# xval=(x_values-np.min(x_values))*2\n",
    "# ax.plot(xval,xval*8,'k--')\n",
    "ax.set_xlim([.03,4])\n",
    "ax.set_ylim([.01,ylim])\n",
    "ax.set_xlabel('lag (s)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:13:26.105Z"
    }
   },
   "outputs": [],
   "source": [
    "#save msd xy values as csv\n",
    "file_out_boot=os.path.join(os.path.dirname(os.path.dirname(list_of_files[0])),f'bootstrapped_{basestr}_bins_{bins}.csv')\n",
    "df_bootstrapped=pd.DataFrame({\n",
    "    'lagt_sec':x_values, 'msd_cm2':y_values, 'Delta_msd_cm2':y_err_values, 'hat_msd_cm2':y_hat_values\n",
    "})\n",
    "df_bootstrapped.to_csv(file_out_boot,index=False)\n",
    "print('bootstrapped results saved in:')\n",
    "print(file_out_boot)\n",
    "beep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-13T03:13:27.226Z"
    }
   },
   "outputs": [],
   "source": [
    "#Control /home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_0_varkappa_0/bootstrapped_msd_particle_bins_30.csv\n",
    "# #fitting from this particle model gave D=2.00(1) cm^2/s, as expected\n",
    "# xscale=0.001 #seconds per ms\n",
    "# xmin=10. #ms\n",
    "# xmax=2000 #ms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## (optional) repeat computation of D with the apparently less precise method of weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:10.986863Z",
     "start_time": "2021-08-13T01:01:10.561Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#extract values\n",
    "x_scale=0.001 #sec per ms\n",
    "x_values = df_in['lagt'].values*x_scale\n",
    "y_values = df_in['msd'].values/x_values\n",
    "\n",
    "#bin and bootstrap results\n",
    "bins = 30#'auto'  #\n",
    "dict_out = bin_and_bootstrap_xy_values(x=x_values,\n",
    "                                       y=y_values,\n",
    "                                       xlabel='lagt',\n",
    "                                       ylabel='y',\n",
    "                                       bins=bins,\n",
    "                                       min_numobs=None,\n",
    "                                       num_bootstrap_samples=1000,\n",
    "                                       npartitions=npartitions)\n",
    "df_msdt = pd.DataFrame(dict_out)\n",
    "df_msdt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:10.988204Z",
     "start_time": "2021-08-13T01:01:10.564Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#compute D_apparent using a weighted average\n",
    "j0=1 #first value to use\n",
    "x=df_msdt['lagt'].values[j0:]\n",
    "y=df_msdt['y'].values[j0:]/4\n",
    "y_err=df_msdt['Delta_y'].values[j0:]/4\n",
    "w=df_msdt['counts'].values[j0:]\n",
    "w=w/np.sum(w)\n",
    "D_apparent=np.sum(w*y)\n",
    "#estimate 95% CI of D_apparent using a weighted average\n",
    "Delta_D_apparent=np.sqrt(np.sum(w*y_err**2))\n",
    "print(f\"The weighted average of each lag bin was\")\n",
    "print(f\"D_apparent={D_apparent:.4f}+-{Delta_D_apparent:.4f} cm^2/s\")\n",
    "print(f\"The mean time between two lag bins was {np.mean(np.diff(x)):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:10.990117Z",
     "start_time": "2021-08-13T01:01:10.568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from lib.viewer.bluf.plot_func import *\n",
    "fontsize=18\n",
    "alpha=0.5\n",
    "c='C3'\n",
    "elinewidth=3\n",
    "markersize=4\n",
    "capsize=3\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "#naive plot of MSD/lagt versus lagt\n",
    "x=df_msdt['lagt'].values\n",
    "y=df_msdt['y'].values/4\n",
    "y_err=df_msdt['Delta_y'].values/4\n",
    "ax.errorbar(x,y,y_err,c=c,\n",
    "            alpha=alpha,\n",
    "            fmt='o',\n",
    "            markersize=markersize,\n",
    "            ecolor=c,\n",
    "            elinewidth=elinewidth,\n",
    "            errorevery=1,\n",
    "            capsize=capsize\n",
    "           )\n",
    "ax.plot(x,0.*x+8/4,'k-')\n",
    "format_plot_general(ax=ax,xlabel=r'$\\tau$ (seconds)',ylabel=r'MSD$/4\\tau$ (cm$^2$/s)',fontsize=fontsize,use_loglog=False)#,**kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:10.991565Z",
     "start_time": "2021-08-13T01:01:10.572Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from lib import *\n",
    "# from lib.viewer.PlotMeanSquaredDisplacements import PlotMeanSquaredDisplacements\n",
    "\n",
    "# df=pd.read_csv(input_fn)\n",
    "# #compute t0 and tf for each particle\n",
    "# dft=df.groupby(pid_col)[t_col].describe()\n",
    "# dft0=dft['min']\n",
    "# dftf=dft['max']\n",
    "\n",
    "# #compute t1 and t2 for each particle\n",
    "# dft1=dft0+crop_start_by\n",
    "# dft2=dftf-crop_end_by\n",
    "\n",
    "# #get the list of particles dft2-dft1 \\ge minimum_lifetime\n",
    "# dflifetime_considered=dft2-dft1\n",
    "# pid_values_to_consider=dflifetime_considered[dflifetime_considered>=minimum_lifetime].index.values\n",
    "\n",
    "# # for pid in pid_values_to_consider[:]:\n",
    "# #     #     lagt_values,msd_values=compute_individual_mean_squared_displacement(df,dft1,dft2,DT,pid,pid_col=pid_col)\n",
    "# #     lagt_values,msd_values=df_msd_example[df_msd_example['pid']==pid][['lagt','msd']].values.T\n",
    "# #     ax.plot(lagt_values*xscale,msd_values,alpha=0.4,color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:10.993302Z",
     "start_time": "2021-08-13T01:01:10.576Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df_msd_example=compute_each_mean_squared_displacement(input_fn,**kwargs)\n",
    "# df_msd_example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:10.995751Z",
     "start_time": "2021-08-13T01:01:10.584Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:10.998830Z",
     "start_time": "2021-08-13T01:01:10.589Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #TODO(later): make text interface for choosing new max_lagtime. Note max_lagtime is in units of frames, not time...\n",
    "# print(f\"If you want to save memory and decrease runtime decide on a reasonable value for max_lagtime!  maxt={max_lagtime}\")\n",
    "\n",
    "#TODO: load all of ^those imsd into python and compute the mean imsd, binning by lagt\n",
    "#TODO: save resulting emsd to csv\n",
    "#TODO: generate plots\n",
    "#TODO: look at plots and decide whether to change the default tau_min and tau_max\n",
    "#TODO: compute linear regression with tau_min and tau_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# compute D \n",
    "\n",
    "as the mean value of D computed on a trial by trial basis.  Bootstrap to compute Delta_D\n",
    "\n",
    "- DONE: try per trial basis\n",
    "- TODO: try per particle basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:10.999889Z",
     "start_time": "2021-08-13T01:01:10.593Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO: verify that I moved this to lib and added the effected .py file to __init__.py\n",
    "def compute_D(df,xscale=0.001,xmin=0.,xmax=500.):\n",
    "    #compute the linear fit of bootstrapped msd\n",
    "    #     df=df_emsd\n",
    "    #     xscale=0.001 #seconds per ms\n",
    "    #     xmin=0. #ms\n",
    "    #     xmax=500 #ms\n",
    "    xmin*=xscale\n",
    "    xmax*=xscale\n",
    "    x_values=df['lagt'].values*xscale\n",
    "    y_values=df['msd'].values\n",
    "    x_err_values=df['Delta_lagt'].values\n",
    "    y_err_values=df['Delta_msd'].values\n",
    "    counts=df['counts'].values\n",
    "\n",
    "    #fit drdt_values to F0+F1/r with OLS fit for LR model where 1/r is greater than some 1/cm\n",
    "    boo=(x_values>xmin)&(x_values<xmax)\n",
    "    x=x_values[boo]\n",
    "    y=y_values[boo]\n",
    "    dict_force_fit=compute_95CI_ols(x,y)\n",
    "    y_hat_values=dict_force_fit['b']+dict_force_fit['m']*x_values\n",
    "\n",
    "    #(optional) rename specific values\n",
    "    dict_force_fit=dict_force_fit\n",
    "    y_hat_values=y_hat_values\n",
    "    D=dict_force_fit['m']/4\n",
    "    return D\n",
    "    \n",
    "#     #bluf\n",
    "#     print(f\"the ols fit for diffusion coefficient, D={:.4f} is:\")\n",
    "#     print_dict(dict_force_fit)\n",
    "#     print(f\"Nobs= {np.mean(counts):.0f} +- {np.std(counts):.0f}\")\n",
    "#     print(f\"trial_folder_name: {trial_folder_name}\")\n",
    "\n",
    "def return_compute_D(msd_fn,bins='auto'):\n",
    "    ''''''\n",
    "    df_in=pd.read_csv(msd_fn)\n",
    "    #extract values\n",
    "    lagt_values = df_in['lagt'].values\n",
    "    msd_values = df_in['msd'].values\n",
    "    #bin and bootstrap results\n",
    "    #'auto'  #\n",
    "    df_emsd = bin_and_bootstrap_xy_values(x=lagt_values,\n",
    "                                           y=msd_values,\n",
    "                                           xlabel='lagt',\n",
    "                                           ylabel=r'msd',\n",
    "                                           bins=bins,\n",
    "                                           min_numobs=None,\n",
    "                                           num_bootstrap_samples=1000,\n",
    "                                           npartitions=npartitions,\n",
    "                                         printing=False)\n",
    "    return compute_D(df_emsd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.000996Z",
     "start_time": "2021-08-13T01:01:10.597Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #input_fn is any sort of trajectory .csv file.  it must have a column reffered to by pid_col that uniquely identifies each particle\n",
    "# #Load example particle Log file where I want to compute MSD and tracking has already been done \n",
    "# #(good): data that uses explicit particle tracking\n",
    "# # input_fn=search_for_file()\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_0_varkappa_0/Log/pbc_particle_log1_log.csv\"\n",
    "# # input_fn='/Users/timothytyree/Documents/GitHub/care/notebooks/Data/test_data/pbc_particle_log69_log.csv'\n",
    "\n",
    "#TODO: no attraction, no annihilation\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_0_varkappa_0/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "#TODO: no attraction with annihilation\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_0/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "#TODO: attraction with annihilation\n",
    "\n",
    "#TODO: attraction with annihilation but without diffusion\n",
    "\n",
    "# #TODO: full models\n",
    "\n",
    "# def return_msd_particle_average(input_fn,pid_col='pid_explicit',t_col='t',ds=10,width=10,height=10,\n",
    "#                                 **kwargs):\n",
    "#     '''    \n",
    "#     input_fn is a .csv locating a trajectory file with particles identified by pid_col \n",
    "#     and time indicated by t_col\n",
    "#     ds is the total domain size and width and height are the number of length units / pixels afforded to the original computational domain.\n",
    "#     kwargs are passed to unwrap_traj_and_center\n",
    "    \n",
    "#     previously named return_msd_phys\n",
    "#     TODO: GPU accelerate this pandas-like function with rapids cudf\n",
    "#     '''\n",
    "#     df=pd.read_csv(input_fn)\n",
    "#     trial_folder_name=os.path.dirname(os.path.dirname(input_fn))\n",
    "    \n",
    "    \n",
    "#     #(bad)particle data analyzed using full model pipeline\n",
    "#     # input_fn=\"/Users/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_0/trajectories_unwrap/pbc_particle_log121_traj_sr_30_mem_0_unwrap.csv\"\n",
    "#     # width=10 #width of computational domain\n",
    "#     # ds   =10  #cm\n",
    "#     # #from here on, we will use units in terms of those used by the full model\n",
    "#     # height=width\n",
    "#     DS=ds/width\n",
    "\n",
    "#     #unwrap trajectories\n",
    "#     pid_lst = sorted(set(df[pid_col].values))\n",
    "#     #(duplicates filtered earlier in full model pipeline.  Unnecessary in particle model with explicit tracking_ _  _ _ ) filter_duplicate_trajectory_indices is slow (and can probs be accelerated with a sexy pandas one liner)\n",
    "#     # pid_lst_filtered = filter_duplicate_trajectory_indices(pid_lst,df)\n",
    "#     df = pd.concat([unwrap_traj_and_center(df[df[pid_col]==pid], width, height, **kwargs) for pid in pid_lst])\n",
    "#     DT=get_DT(df,pid_col=pid_col) #ms\n",
    "#     df[df.frame==2].describe()\n",
    "#     df['sd']=df['x']**2+df['y']**2\n",
    "#     d_msd=df.groupby('t')['sd'].mean()\n",
    "#     lagt_values=d_msd.index.values\n",
    "#     msd_values=d_msd.values\n",
    "#     return lagt_values,msd_values\n",
    "\n",
    "# def compute_D_OLS_2D(lagt_values,msd_values,\n",
    "#                 tmin=0,\n",
    "#                 tmax=0,\n",
    "#                 tscale=0.001,\n",
    "#                 DS=1.):\n",
    "#     xmin=tmin*tscale\n",
    "#     xmax=tmax*tscale\n",
    "#     x_values=lagt_values*tscale\n",
    "#     y_values=msd_values*DS**2\n",
    "#     # x_err_values=df['Delta_lagt'].values\n",
    "#     # y_err_values=df['Delta_msd'].values\n",
    "#     # counts=df['counts'].values\n",
    "\n",
    "#     #fit drdt_values to F0+F1/r with OLS fit for LR model where 1/r is greater than some 1/cm\n",
    "#     boo=(x_values>xmin)&(x_values<xmax)\n",
    "#     x=x_values[boo]\n",
    "#     y=y_values[boo]\n",
    "#     dict_force_fit=compute_95CI_ols(x,y)\n",
    "#     y_hat_values=dict_force_fit['b']+dict_force_fit['m']*x_values\n",
    "\n",
    "#     #(optional) rename specific values\n",
    "#     dict_force_fit=dict_force_fit\n",
    "#     y_hat_values=y_hat_values\n",
    "#     D=dict_force_fit['m']/4\n",
    "#     Delta_D=dict_force_fit['D']/4\n",
    "#     dict_out={\n",
    "#         'D':D,\n",
    "#         'Delta_D':Delta_D,\n",
    "#         'Rsquared':dict_force_fit['Rsquared']\n",
    "#     }\n",
    "#     return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.002122Z",
     "start_time": "2021-08-13T01:01:10.601Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D_apparent_lst=[]\n",
    "for fn in list_of_files:\n",
    "    D_apparent_lst.append(return_compute_D(fn))\n",
    "    \n",
    "print(np.mean(D_apparent_lst))\n",
    "print(np.std(D_apparent_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.003167Z",
     "start_time": "2021-08-13T01:01:10.605Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.004641Z",
     "start_time": "2021-08-13T01:01:10.609Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=13\n",
    "print(np.gmean(D_apparent_lst[:n]))\n",
    "print(np.std(D_apparent_lst[:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.006066Z",
     "start_time": "2021-08-13T01:01:10.614Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# def geo_mean_overflow(iterable):\n",
    "#     a = np.log(iterable)\n",
    "#     return np.exp(a.mean())\n",
    "\n",
    "geo_mean_overflow(D_apparent_lst),np.median(D_apparent_lst),np.mean(D_apparent_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T03:28:49.346818Z",
     "start_time": "2021-07-23T03:28:49.282115Z"
    },
    "hidden": true
   },
   "source": [
    "I doubt computing individual particle's D values will have a significant effect on the average value when breaking up by trial did not...\n",
    "\n",
    "It would lend itself to filtering any false tips\n",
    "\n",
    "The ensemble-averaged mean squared displacement was computed according to \n",
    "$$\n",
    "\\text{MSD}(\\tau)=\\mathbb{E}\\Big[ (r(\\tau) - r(0) )^2  \\Big]_\\text{particles}\n",
    "$$\n",
    "\n",
    "\n",
    "The time-averaged mean squared displacement was computed according to \n",
    "$$\n",
    "\\Delta^2(\\tau)=\\mathbb{E}\\Big[ (r(t+\\tau) - r(t) )^2  \\Big]_\\text{t}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.007264Z",
     "start_time": "2021-08-13T01:01:10.618Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(input_fn)\n",
    "unwrap_trajectories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.008760Z",
     "start_time": "2021-08-13T01:01:10.623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pid_col='pid_explicit'\n",
    "t_values=np.array(sorted(set(df.t.values)))\n",
    "pid_values=np.array(sorted(set(df[pid_col].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.009967Z",
     "start_time": "2021-08-13T01:01:10.627Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t0=np.min(t_values)\n",
    "x0_values=df.loc[df.t==t0,'x'].values\n",
    "y0_values=df.loc[df.t==t0,'y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.011236Z",
     "start_time": "2021-08-13T01:01:10.631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for pid in pid_values:\n",
    "#     #select particle and extract trajectory\n",
    "#     #subtract off initial position\n",
    "#     #compute the norm / magnitude of the net displacement at each time point\n",
    "#     #add each time point to a running total at each time point\n",
    "#     #increment the count of observations at each time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.012567Z",
     "start_time": "2021-08-13T01:01:10.637Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# xyt_values=df[df[pid_col]==pid][['x','y','t']].values\n",
    "# xyt_values-=xyt_values[0]\n",
    "# lag_values=xyt_values[:,-1]\n",
    "# displacement_values=xyt_values[:,:2]\n",
    "# displacement_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.013684Z",
     "start_time": "2021-08-13T01:01:10.641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.014815Z",
     "start_time": "2021-08-13T01:01:10.646Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#all CPU version\n",
    "b = db.from_sequence(input_fn_lst, npartitions=npartitions).map(return_msd_particle_average)\n",
    "start = time.time()\n",
    "tuple_lst=list(b)\n",
    "# D_apparent_lst = list(b)\n",
    "# print(f\"run time for computing mean squared displacements was {time.time()-start:.2f} seconds.\")\n",
    "# beep(3)\n",
    "# print((geo_mean_overflow(D_apparent_lst),np.median(D_apparent_lst),np.mean(D_apparent_lst),np.std(D_apparent_lst)))\n",
    "# list_of_files=retval\n",
    "# list_of_files=[fn for fn in list_of_files if type(fn)==type(str()) and fn.find('Warning:')==-1]\n",
    "# # list_of_files=[fn for fn in list_of_files if fn.find('Warning:')==-1]\n",
    "# print(f\"wrote {len(list_of_files)} output files to a common folder\")\n",
    "# assert (len(list_of_files)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Testing a straight forward computation of D, where we average over space first...\n",
    "\n",
    "```\n",
    "run time for computing mean squared displacements was 386.86 seconds.\n",
    "(2.2207477027140863, 2.048612039525339, 2.759752260725528, 3.392611667160421)\n",
    "```\n",
    "\n",
    "So... Those don't match except for the median...\n",
    "\n",
    "\n",
    "TODO: try computing the sum and the count for each time bin over all particles found in all trajectory files...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:04:56.487172Z",
     "start_time": "2021-06-23T23:04:56.468839Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# compute dRdt versus R with unconditioned sampling\n",
    "- DONE: token example from particle model\n",
    "- DONE: full model (FK)\n",
    "- TODO: full model (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.015793Z",
     "start_time": "2021-08-13T01:01:10.651Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from lib.measure.bootstrap import bin_and_bootstrap_xy_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T20:32:13.119240Z",
     "start_time": "2021-07-21T20:32:13.099755Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.017213Z",
     "start_time": "2021-08-13T01:01:10.657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#input_fn is any sort of trajectory .csv file.  it must have a column reffered to by pid_col that uniquely identifies each particle\n",
    "#Load example particle Log file where I want to compute MSD and tracking has already been done \n",
    "#(good): data that uses explicit particle tracking\n",
    "input_fn=search_for_file()\n",
    "\n",
    "#DONE: no attraction, no annihilation\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_0_varkappa_0/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "#TODO(later): no attraction with annihilation\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_0/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "#DONE: attraction with annihilation but without diffusion\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_0_L_10_kappa_1500_varkappa_5/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "#DONE: attraction with annihilation but with diffusion\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_5/Log/pbc_particle_log1_log.csv\"\n",
    "\n",
    "# input_fn='/Users/timothytyree/Documents/GitHub/care/notebooks/Data/test_data/pbc_particle_log69_log.csv'\n",
    "trial_folder_name=os.path.dirname(os.path.dirname(input_fn))\n",
    "pid_col='pid_explicit'\n",
    "t_col='t'\n",
    "width=10 #width of computational domain\n",
    "ds   =10  #cm\n",
    "\n",
    "\n",
    "# input_fn='/Users/timothytyree/Documents/GitHub/care/notebooks/Data/test_data/pbc_particle_log69_log.csv'\n",
    "trial_folder_name=os.path.dirname(os.path.dirname(input_fn))\n",
    "pid_col='particle'\n",
    "t_col='t'\n",
    "width=200 #width of computational domain\n",
    "ds   =5  #cm\n",
    "\n",
    "\n",
    "#(bad)particle data analyzed using full model pipeline\n",
    "# input_fn=\"/Users/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_0/trajectories_unwrap/pbc_particle_log121_traj_sr_30_mem_0_unwrap.csv\"\n",
    "df=pd.read_csv(input_fn)\n",
    "kwargs={}\n",
    "\n",
    "#from here on, we will use units in terms of those used by the full model\n",
    "height=width\n",
    "DS=ds/width\n",
    "DT=get_DT(df,pid_col=pid_col);print(f\"DT={DT} ms\")\n",
    "#print summary stats on particle lifetimes for one input folder\n",
    "dft=df.groupby(pid_col)[t_col].describe()\n",
    "df_lifetimes=-dft[['max','min']].T.diff().loc['min']\n",
    "\n",
    "print(f\"printing summary stats on particle lifetimes for one input folder in {trial_folder_name}:\")\n",
    "print(df_lifetimes.describe())\n",
    "# print(df_lifetimes.head(10))\n",
    "print(\"\\nPlease manually review the key word arguments in kwargs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.018422Z",
     "start_time": "2021-08-13T01:01:10.661Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO(later): update this block with the kwargs for get_routine_for_computing_dRdt_in_bulk\n",
    "# tmin=0#ms\n",
    "tmin=100#ms\n",
    "frame_min=int(tmin/DT) #first frame to consider for this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.019669Z",
     "start_time": "2021-08-13T01:01:10.664Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: update routine_for_computing_dRdt_in_bulk to use pid_col instead of particle\n",
    "#TODO: figure out the conversion from crop_start_by amd crop_end_by for use in routine_for_computing_dRdt_in_bulk\n",
    "kwargs={\n",
    "    'DT':DT,\n",
    "    'ds':ds,\n",
    "    'width':width,\n",
    "    'pid_col':pid_col,\n",
    "    't_col':t_col,\n",
    "    'use_drop_shorter_than':True,\n",
    "   'drop_shorter_than':50,#150, #ms\n",
    "   'round_t_to_n_digits':5,\n",
    "   'frame_min':frame_min,\n",
    "   'num_frames_between':1,\n",
    "   'use_random_frames':False,\n",
    "   'num_random_frames':50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.020891Z",
     "start_time": "2021-08-13T01:01:10.668Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_all_longer_than"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.022042Z",
     "start_time": "2021-08-13T01:01:10.672Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "use_test=True\n",
    "routine_for_computing_dRdt_in_bulk = get_routine_for_computing_dRdt_in_bulk(**kwargs)\n",
    "if use_test:\n",
    "    #optionally test the routine\n",
    "    retval=routine_for_computing_dRdt_in_bulk(input_fn)\n",
    "    print(pd.read_csv(retval).head())\n",
    "\n",
    "def routine(input_fn):\n",
    "    try:\n",
    "        return routine_for_computing_dRdt_in_bulk(input_fn)\n",
    "    except Exception as e:\n",
    "        return f\"Warning: something went wrong, {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.023177Z",
     "start_time": "2021-08-13T01:01:10.675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trial_folder_name=os.path.dirname(os.path.dirname(input_fn))\n",
    "npartitions=os.cpu_count()\n",
    "npartitions=8\n",
    "\n",
    "input_fn_lst=get_log_files(trial_folder_name, extension='/trajectories/', trgt='.csv')\n",
    "# input_fn_lst=get_log_files(trial_folder_name, extension='/Log/', trgt='.csv')\n",
    "# # input_fn_lst=get_log_files(trial_folder_name, extension='', trgt='.csv')\n",
    "print(f\"We're about to use {npartitions} cores to obliterate {len(input_fn_lst)} trajectory files from {trial_folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.024338Z",
     "start_time": "2021-08-13T01:01:10.679Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# WARNING: this took 8 hours for 200 trials over 12 cores...\n",
    "# ^this suggests a run time of ~30 minutes per file\n",
    "#all CPU version\n",
    "b = db.from_sequence(input_fn_lst, npartitions=npartitions).map(routine)\n",
    "start = time.time()\n",
    "retval = list(b)\n",
    "print(f\"run time for computing mean squared displacements was {time.time()-start:.2f} seconds.\")\n",
    "beep(3)\n",
    "\n",
    "list_of_files=retval\n",
    "list_of_files=[fn for fn in list_of_files if type(fn)==type(str()) and fn.find('Warning:')==-1]\n",
    "# list_of_files=[fn for fn in list_of_files if fn.find('Warning:')==-1]\n",
    "print(f\"wrote {len(list_of_files)} output files to a common folder\")\n",
    "assert (len(list_of_files)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.025576Z",
     "start_time": "2021-08-13T01:01:10.683Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "find_list_of_files=False\n",
    "\n",
    "#merge all csv files into one big-ol' csv file\n",
    "pid_col='pid'\n",
    "folder_out_name=os.path.basename(os.path.dirname(fn))\n",
    "save_fn=folder_out_name+'.csv'\n",
    "file_out=os.path.join(os.path.dirname(os.path.dirname(list_of_files[0])),save_fn)\n",
    "folder_name=folder_out_name\n",
    "# folder_name='/radial_neighbor_velocities_framemin_4000_numframesbetween_1_maxdistthrsh_5/'\n",
    "if find_list_of_files:\n",
    "    #find all files successfully saved for computing dRdt in bulk\n",
    "    trial_folder_name=os.path.dirname(os.path.dirname(input_fn))\n",
    "    list_of_files=get_log_files(trial_folder_name, extension=folder_name, trgt='.csv')\n",
    "    assert (len(list_of_files)>0)\n",
    "    print(len(list_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.026760Z",
     "start_time": "2021-08-13T01:01:10.688Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO: add pid field to dRdt data unconditioned on annihilation\n",
    "#TODO: add event_id field to dRdt data\n",
    "provide_event_id=False\n",
    "#merge all csv files into one big-ol' csv file\n",
    "file_in=os.path.join(trial_folder_name,f'drdt_'+save_fn)\n",
    "# file_in=os.path.join(trial_folder_name,f'drdt.csv')\n",
    "reval=produce_one_csv(list_of_files, file_in,provide_event_id=provide_event_id)#, encoding=\"utf-8\")\n",
    "print('merged results saved in:')\n",
    "print(file_in)\n",
    "beep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.027836Z",
     "start_time": "2021-08-13T01:01:10.692Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DONE: check routine_for_computing_dRdt_in_bulk outputs R in cm and dRdt in cm/s\n",
    "# ^that computes DS=ds/width and passes DS to comp_radial_velocities_between_frames, which scales output from raw according to \n",
    "# #compute dRdt and average R for those tips\n",
    "# dRdt_out=DS*(R_nxt-R_prv)/DT\n",
    "# #optionally, measure range from previous time point only\n",
    "# if use_forward_R:\n",
    "#     R_out=R_prv\n",
    "# else:\n",
    "#     R_out=DS*0.5*(R_nxt+R_prv)\n",
    "\n",
    "#all drdt for all bulk in \n",
    "# file_in=\"/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_5/drdt.csv\"\n",
    "\n",
    "#load an enormous number of samples into a pandas.DataFrame\n",
    "df_in=pd.read_csv(file_in)\n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.028859Z",
     "start_time": "2021-08-13T01:01:10.700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bins=20#30#'auto'#\n",
    "#extract values\n",
    "r_values=df_in['r'].values\n",
    "drdt_values=df_in['drdt'].values\n",
    "\n",
    "from lib.measure.bootstrap import bin_and_bootstrap_xy_values\n",
    "import dask.bag as db\n",
    "num_bootstrap_samples=1000\n",
    "min_numobs=None\n",
    "# file_in='/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_0/drdt.csv'\n",
    "npartitions=os.cpu_count()\n",
    "#load an enormous number of samples into a pandas.DataFrame\n",
    "df_in=pd.read_csv(file_in)\n",
    "#extract values\n",
    "xlabel='r'\n",
    "ylabel='drdt'\n",
    "x_values=df_in[xlabel].values\n",
    "y_values=df_in[ylabel].values\n",
    "\n",
    "#bin and bootstrap results\n",
    "npartitions=os.cpu_count()\n",
    "dict_out = bin_and_bootstrap_xy_values(x=x_values,\n",
    "                                       y=y_values,\n",
    "                                       xlabel=xlabel,\n",
    "                                       ylabel=ylabel,\n",
    "                                       bins=bins,\n",
    "                                       min_numobs=min_numobs,\n",
    "                                       num_bootstrap_samples=num_bootstrap_samples,\n",
    "                                       npartitions=npartitions)\n",
    "df_drdt = pd.DataFrame(dict_out)\n",
    "df_drdt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T20:26:03.038704Z",
     "start_time": "2021-07-23T20:26:03.017179Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.029847Z",
     "start_time": "2021-08-13T01:01:10.707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#save ensemble drdt\n",
    "#merge all csv files into one big-ol' csv file\n",
    "# file_out=os.path.join(os.path.dirname(os.path.dirname(list_of_files[0])),f'ensemble_drdt_bins_{bins}.csv')\n",
    "file_out=os.path.join(os.path.dirname(file_in),f'ensemble_drdt_numfiles_{num_files}_bins_{bins}.csv')\n",
    "df_drdt.to_csv(file_out,index=False)\n",
    "print('merged results saved in:')\n",
    "print(file_out)\n",
    "beep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.030849Z",
     "start_time": "2021-08-13T01:01:10.712Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#compute the fit\n",
    "df=df_drdt\n",
    "rmin=0. #cm\n",
    "rmax=4 #cm\n",
    "tscale=0.001 #sec per ms\n",
    "lscale=1. #cm per cm\n",
    "r_values=df['r'].values*lscale\n",
    "drdt_values=df['drdt'].values/tscale*lscale\n",
    "Delta_r_values=df['Delta_r'].values*lscale\n",
    "Delta_drdt_values=df['Delta_drdt'].values/tscale*lscale\n",
    "counts=df['counts'].values\n",
    "\n",
    "#fit drdt_values to F0+F1/r with OLS fit for LR model where 1/r is greater than some 1/cm\n",
    "x_values=r_values\n",
    "y_values=drdt_values\n",
    "x_err_values=Delta_r_values\n",
    "y_err_values=Delta_drdt_values\n",
    "\n",
    "#fit drdt_values to F0+F1/r with OLS fit for LR model where 1/r is greater than some 1/cm\n",
    "boo=(r_values>rmin)&(r_values<rmax)\n",
    "x=1/r_values[boo]\n",
    "y=drdt_values[boo]\n",
    "dict_force_fit=compute_95CI_ols(x,y)\n",
    "y_hat_values=dict_force_fit['b']+dict_force_fit['m']/r_values\n",
    "\n",
    "#(optional) rename specific values\n",
    "dict_force_fit=dict_force_fit\n",
    "y_hat_values=y_hat_values\n",
    "\n",
    "#bluf\n",
    "print(f\"varkappa_apparent={dict_force_fit['m']:.3f}+-{dict_force_fit['Delta_m']:.3f}\")\n",
    "print(f\"the ols fit was computed from {rmin:.3f} to {rmax:.3f} cm:\")\n",
    "print_dict(dict_force_fit)\n",
    "print(f\"Nobs= {np.mean(counts):.0f} +- {np.std(counts):.0f}\")\n",
    "print(f\"trial_folder_name: {trial_folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T19:13:53.642567Z",
     "start_time": "2021-07-28T19:13:53.616637Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.031856Z",
     "start_time": "2021-08-13T01:01:10.718Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ylim=250#25\n",
    "c='C0'\n",
    "yscale=1.\n",
    "xlim=np.max(x_values)-.01\n",
    "#plot mean radial velocities\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(9, 4))\n",
    "PlotMeanRadialVelocities(axs, x_values, y_values*yscale, y_err_values*yscale, y_hat_values*yscale,c=c,#c='C3',\n",
    "    alpha=0.4,\n",
    "    fontsize=18,\n",
    "    elinewidth=3,\n",
    "    markersize=4,\n",
    "    capsize=3,\n",
    "    xlim0=[0, xlim],\n",
    "    xlim1=[0, 60])#4])\n",
    "axs[0].plot(x_values*1.1-np.min(x_values),0.*x_values,'k--',alpha=0.7)\n",
    "axs[1].plot((x_values-np.min(x_values))*5,0.*x_values,'k--',alpha=0.7)\n",
    "axs[0].set_ylim([-ylim,ylim])\n",
    "\n",
    "axs[1].set_ylim([-ylim,ylim])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.032878Z",
     "start_time": "2021-08-13T01:01:10.722Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#extract values\n",
    "r_values=df_in['r'].values\n",
    "drdt_values=df_in['drdt'].values\n",
    "\n",
    "from lib.measure.bootstrap import bin_and_bootstrap_xy_values\n",
    "import dask.bag as db\n",
    "num_bootstrap_samples=1000\n",
    "bins='auto'\n",
    "min_numobs=None\n",
    "# file_in='/home/timothytyree/Documents/GitHub/bgmc/python/data/local_results/euic_False_fc_2_r_0.1_D_2_L_10_kappa_1500_varkappa_0/drdt.csv'\n",
    "npartitions=os.cpu_count()\n",
    "#load an enormous number of samples into a pandas.DataFrame\n",
    "df_in=pd.read_csv(file_in)\n",
    "#extract values\n",
    "xlabel='r'\n",
    "ylabel='drdt'\n",
    "x_values=df_in[xlabel].values\n",
    "y_values=df_in[ylabel].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.033998Z",
     "start_time": "2021-08-13T01:01:10.727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#extract values\n",
    "npartitions=os.cpu_count()\n",
    "#extract values\n",
    "xlabel='r'\n",
    "ylabel='rdrdt'\n",
    "x_values=df_in['r'].values\n",
    "y_values=df_in['drdt'].values*x_values\n",
    "num_bootstrap_samples=1000\n",
    "min_numobs=None\n",
    "#bin and bootstrap results\n",
    "bins=30#'auto'\n",
    "npartitions=os.cpu_count()\n",
    "dict_out = bin_and_bootstrap_xy_values(x=x_values,\n",
    "                                       y=y_values,\n",
    "                                       xlabel=xlabel,\n",
    "                                       ylabel=ylabel,\n",
    "                                       bins=bins,\n",
    "                                       min_numobs=min_numobs,\n",
    "                                       num_bootstrap_samples=num_bootstrap_samples,\n",
    "                                       npartitions=npartitions)\n",
    "df_rdrdt = pd.DataFrame(dict_out)\n",
    "df_rdrdt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.035237Z",
     "start_time": "2021-08-13T01:01:10.732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#estimate varkappa using weighted average\n",
    "xmin=0\n",
    "xmax=1\n",
    "x=df_rdrdt[xlabel].values\n",
    "boo=(x>=xmin)&(x<=xmax)\n",
    "y=df_rdrdt[ylabel].values[boo]/xscale\n",
    "y_err=df_rdrdt[f'Delta_{ylabel}'].values[boo]/xscale\n",
    "w=df_rdrdt['counts'].values[boo]\n",
    "w=w/np.sum(w)\n",
    "varkappa_apparent=np.sum(w*y)\n",
    "#estimate 95% CI of D_apparent using a weighted average\n",
    "Delta_varkappa_apparent=np.sqrt(np.sum(w*y_err**2))\n",
    "print(f\"The weighted average of each R bin was\")\n",
    "print(f\"varkappa_apparent={varkappa_apparent:.4f}+-{Delta_varkappa_apparent:.4f} cm^2/s\")\n",
    "print(f\"The mean distance between two R bins was {np.mean(np.diff(x[boo])):.3f} cm\")\n",
    "print(f\"This weighted average considered {xmin}<=R<={xmax} cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.036699Z",
     "start_time": "2021-08-13T01:01:10.736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from lib.viewer.bluf.plot_func import *\n",
    "xscale=0.001\n",
    "fontsize=18\n",
    "alpha=0.5\n",
    "c='C0'\n",
    "elinewidth=3\n",
    "markersize=4\n",
    "capsize=3\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "#naive plot of dRdt*R versus R\n",
    "x=df_rdrdt[xlabel].values\n",
    "y=df_rdrdt[ylabel].values/xscale\n",
    "y_err=df_rdrdt[f'Delta_{ylabel}'].values/xscale\n",
    "ax.errorbar(x,y,y_err,c=c,\n",
    "            alpha=alpha,\n",
    "            fmt='o',\n",
    "            markersize=markersize,\n",
    "            ecolor=c,\n",
    "            elinewidth=elinewidth,\n",
    "            errorevery=1,\n",
    "            capsize=capsize\n",
    "           )\n",
    "ax.plot(x,0.*x-5,'k-')\n",
    "ax.plot(x,0.*x,'k--')\n",
    "ax.set_ylim([-6,4])\n",
    "format_plot_general(ax=ax,xlabel=r'R (cm)',ylabel=r'$R\\,dR/dt$ (cm$^2$/s)',fontsize=fontsize,use_loglog=False)#,**kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-13T01:01:11.037747Z",
     "start_time": "2021-08-13T01:01:10.741Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
