{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575525ef",
   "metadata": {},
   "source": [
    "# investigating motion of isopotential lines\n",
    "Tim Tyree<br>\n",
    "3.15.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2073b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314a3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3776bfcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.479013Z",
     "start_time": "2023-03-17T04:32:39.705694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timothytyree/.local/lib/python3.8/site-packages/numba/core/types/__init__.py:108: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.\n",
      "  long_ = _make_signed(np.long)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmy_initialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeasure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcurvature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/care/notebooks/lib/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroutines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviewer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/care/notebooks/lib/routines/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kwargs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerate_tip_logs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \u001b[38;5;66;03m#FK model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute_bdrates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrack_tips\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/care/notebooks/lib/routines/generate_tip_logs.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#! /usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Generate Birth Death Rates for Given Initial Conditions\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Method = Find intersections of contours after computing entire contours for each observation (unavoidably slow).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Tim Tyree\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 10.28.2020\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeasure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeasure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#^this import is not the best practice. however, minimalism reigns the pythonic.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/care/notebooks/lib/measure/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/python\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_tips_nonlocal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintersection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/care/notebooks/lib/measure/get_tips_nonlocal.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#use the nonlocal topological method to detect tips.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# also records topologcially preserved values.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Tim Tyree\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#9.13.2021\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m measure\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit, njit\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyped\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numba/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _runtests \u001b[38;5;28;01mas\u001b[39;00m runtests\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types, errors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Re-export typeof\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     typeof, prange, pndindex, gdb, gdb_breakpoint, gdb_init,\n\u001b[1;32m     22\u001b[0m     literally, literal_unroll\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numba/core/types/__init__.py:108\u001b[0m\n\u001b[1;32m    106\u001b[0m intc \u001b[38;5;241m=\u001b[39m _make_signed(np\u001b[38;5;241m.\u001b[39mintc) \u001b[38;5;66;03m# C-compat int\u001b[39;00m\n\u001b[1;32m    107\u001b[0m uintc \u001b[38;5;241m=\u001b[39m _make_unsigned(np\u001b[38;5;241m.\u001b[39muintc) \u001b[38;5;66;03m# C-compat uint\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m long_ \u001b[38;5;241m=\u001b[39m _make_signed(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m)\n\u001b[1;32m    109\u001b[0m ulong \u001b[38;5;241m=\u001b[39m _make_unsigned(np\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    110\u001b[0m longlong \u001b[38;5;241m=\u001b[39m _make_signed(np\u001b[38;5;241m.\u001b[39mlonglong)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'long'"
     ]
    }
   ],
   "source": [
    "from lib.my_initialization import *\n",
    "from lib import *\n",
    "from lib.measure.curvature import *\n",
    "from scipy import ndimage\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841534f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.483379Z",
     "start_time": "2023-03-17T04:32:40.483368Z"
    }
   },
   "outputs": [],
   "source": [
    "#reset matplotlib settings\n",
    "import matplotlib as mpl\n",
    "# sns.reset_orig()\n",
    "mpl.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b06e6",
   "metadata": {},
   "source": [
    "# define module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb66c7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.485409Z",
     "start_time": "2023-03-17T04:32:40.485383Z"
    }
   },
   "outputs": [],
   "source": [
    "def unwind_contour(contour,width,height):\n",
    "    \"\"\"unwind_contour handles pbc\n",
    "    \n",
    "    Example Usage:\n",
    "xy_values = unwind_contour(contour)\n",
    "    \"\"\"\n",
    "    xy0 = contour[0]\n",
    "    return np.array(unwrap_contour(x_values = contour[:,0],\n",
    "                                y_values = contour[:,1], \n",
    "                                width=width, height=height)).T + np.array(xy0)\n",
    "\n",
    "@njit\n",
    "def pbc_robust_shift(xy1,xy2,width,height):\n",
    "    \"\"\"block unwrap one point xy1 to xy2 with 2x2 periodic boundary conditions (pbc).\n",
    "    \n",
    "    Example Usage:\n",
    "xy_shift,mindist = pbc_robust_shift(xy1,xy2,width,height) \n",
    "    \"\"\"\n",
    "    xy1=com_curr\n",
    "    xy2=com_next\n",
    "    xy_shift=np.array((0,0))\n",
    "    mindist = np.linalg.norm(xy1-xy2)\n",
    "    ##the four sides\n",
    "    tmp = np.array((width,0))\n",
    "    dist=np.linalg.norm((xy1+tmp)-xy2)\n",
    "    if dist<mindist:\n",
    "        mindist=dist\n",
    "        xy_shift = tmp\n",
    "    tmp = np.array((-width,0))\n",
    "    dist=np.linalg.norm((xy1+tmp)-xy2)\n",
    "    if dist<mindist:\n",
    "        mindist=dist\n",
    "        xy_shift = tmp\n",
    "    tmp = np.array((0,height))\n",
    "    dist=np.linalg.norm((xy1+tmp)-xy2)\n",
    "    if dist<mindist:\n",
    "        mindist=dist\n",
    "        xy_shift = tmp\n",
    "    tmp = np.array((0,-height))\n",
    "    dist=np.linalg.norm((xy1+tmp)-xy2)\n",
    "    if dist<mindist:\n",
    "        mindist=dist\n",
    "        xy_shift = tmp\n",
    "    ##the four corners\n",
    "    tmp = np.array((-width,-height))\n",
    "    dist=np.linalg.norm((xy1+tmp)-xy2)\n",
    "    if dist<mindist:\n",
    "        mindist=dist\n",
    "        xy_shift = tmp\n",
    "    tmp = np.array((-width,height))\n",
    "    dist=np.linalg.norm((xy1+tmp)-xy2)\n",
    "    if dist<mindist:\n",
    "        mindist=dist\n",
    "        xy_shift = tmp\n",
    "    tmp = np.array((width,-height))\n",
    "    dist=np.linalg.norm((xy1+tmp)-xy2)\n",
    "    if dist<mindist:\n",
    "        mindist=dist\n",
    "        xy_shift = tmp\n",
    "    tmp = np.array((width,height))\n",
    "    dist=np.linalg.norm((xy1+tmp)-xy2)\n",
    "    if dist<mindist:\n",
    "        mindist=dist\n",
    "        xy_shift = tmp\n",
    "    return xy_shift,mindist\n",
    "\n",
    "def comp_msdistance_to_spline(s,*args):\n",
    "    pt_src,tck_dst = args\n",
    "    pt_dst = splev(s, tck_dst)\n",
    "    return np.sum((pt_src-pt_dst)**2)\n",
    "#     return np.linalg.norm(pt_src-pt_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f3028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.487456Z",
     "start_time": "2023-03-17T04:32:40.487441Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: move to lib.model.ep.lr.utils\n",
    "def bilinear_interpolate_state_lr(x_values,y_values,inVc,dVcdt,vx,vy,inmhjdfx):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "x_values = contour[:,0]\n",
    "y_values = contour[:,1]\n",
    "d_state = bilinear_interpolate_state_lr(x_values,y_values,inVc,dVcdt,vx,vy,inmhjdfx)\n",
    "    \"\"\"\n",
    "    # bilinear_interpolate image to sites\n",
    "    width,height=inVc.shape[:2]\n",
    "    # states_txt = interpolate_img(x_values,y_values,width,height,txt)\n",
    "    states_inVc = np.array(interpolate_img(x_values,y_values,width,height,inVc))\n",
    "    states_dVcdt = np.array(interpolate_img(x_values,y_values,width,height,dVcdt))\n",
    "    states_vx = np.array(interpolate_img(x_values,y_values,width,height,vx))\n",
    "    states_vy = np.array(interpolate_img(x_values,y_values,width,height,vy))\n",
    "    states_inmhjdfx = np.array(interpolate_img(x_values,y_values,width,height,inmhjdfx))\n",
    "    d_state = pd.DataFrame(dict(X=x_values,Y=y_values,\n",
    "                                  V=states_inVc[:,0],Ca=states_inVc[:,1],\n",
    "                                  dVdt= states_dVcdt[:,0],dCadt= states_dVcdt[:,1],\n",
    "                                  vX= states_vx,vY= states_vy,\n",
    "                                  m= states_inmhjdfx[:,0],h= states_inmhjdfx[:,1],\n",
    "                                  j= states_inmhjdfx[:,2],d= states_inmhjdfx[:,3],\n",
    "                                  f= states_inmhjdfx[:,4],x= states_inmhjdfx[:,5],\n",
    "                                 ))\n",
    "    return d_state\n",
    "\n",
    "def extract_curvilinear_states_lr(df_contours, contoursa, contoursa_next, vx, vy, inVc, dVcdt, inmhjdfx,\n",
    "                                 s=1,per=1,upsampling_rate=4,**kwargs):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "df_state_curr,df_state_next = extract_curvilinear_states_lr(df_contours, contoursa, contoursa_next, vx, vy, inVc, dVcdt, inmhjdfx)#,s=1,per=1,**kwargs)\n",
    "    \"\"\"\n",
    "    #input: df_contours, contoursa, contoursa_next, vx, vy, inVc, dVcdt, inmhjdfx\n",
    "    #output: df_state_curr,df_state_next\n",
    "    width,height = inVc.shape[:2]\n",
    "    d_state_curr_lst=[]\n",
    "    d_state_next_lst=[]\n",
    "    #for each pair of contours\n",
    "    for ci1,row in df_contours.iterrows():\n",
    "        ci2= int(row['ci_next'])\n",
    "        D0 = row['dist_next']\n",
    "        contour1 = contoursa[ci1]\n",
    "        contour2 = contoursa_next[ci2]\n",
    "\n",
    "        #unwind_contour handles pbc\n",
    "        xy_values1 = unwind_contour(contour1,width,height)\n",
    "        xy_values2 = unwind_contour(contour2,width,height)\n",
    "        #^this might be the hard-to-njit rate-limiting step in a faster contour epoch\n",
    "        #compute cublic spline interpolant\n",
    "        tck, s_values = splprep(xy_values1.T,s=s,per=per)\n",
    "        tck_next, s_values_next = splprep(xy_values2.T,s=s,per=per)\n",
    "        s_values_interpolated = np.linspace(0,1,int(np.ceil(s_values.shape[0]*upsampling_rate)))\n",
    "        pts_curr = np.array(splev(s_values_interpolated, tck))\n",
    "#         pts_next = np.array(splev(s_values_interpolated, tck_next))\n",
    "        #compute current/next states along the contour respecting pbc\n",
    "        d_state_curr = bilinear_interpolate_state_lr(pts_curr[0]%width,pts_curr[1]%height,inVc,dVcdt,vx,vy,inmhjdfx)\n",
    "        d_state_curr['cid']=ci1\n",
    "\n",
    "\n",
    "        #compute linearly interpolated contour positions and curvature\n",
    "#         s_values_interpolated = np.linspace(0,1,int(np.ceil(s_values.shape[0]*upsampling_rate)))\n",
    "#         pts_curr = np.array(splev(s_values_interpolated, tck))\n",
    "        #measure the size and shape of either contour\n",
    "        dxds = np.array(splev(s_values_interpolated, tck, der=1))\n",
    "        dx2ds2 = np.array(splev(s_values_interpolated, tck, der=2))\n",
    "        denom = np.linalg.norm(dxds,axis=0)**3\n",
    "        wz_values = np.cross(dx2ds2,dxds,axis=0)\n",
    "        # wz_values = np.cross(dxds,dx2ds2,axis=0)\n",
    "        #Q: which of ^these has the \"right\" sign?\n",
    "        #compute curvature\n",
    "        curvature_values = wz_values / denom\n",
    "        # curvature_values = np.abs(dx2ds2 * dyds - dxds * dy2ds2) / (dxds * dxds + dyds * dyds)**1.5\n",
    "        d_state_curr['curvature'] = curvature_values\n",
    "\n",
    "\n",
    "        #measure the size and shape of either contour\n",
    "        s_values_interpolated = np.linspace(0,1,int(np.ceil(s_values_next.shape[0]*upsampling_rate)))\n",
    "        pts_next = np.array(splev(s_values_interpolated, tck_next))\n",
    "        d_state_next = bilinear_interpolate_state_lr(pts_next[0]%width,pts_next[1]%height,inVc,dVcdt,vx,vy,inmhjdfx)\n",
    "        d_state_next['cid']=ci2\n",
    "        dxds = np.array(splev(s_values_interpolated, tck_next, der=1))\n",
    "        dx2ds2 = np.array(splev(s_values_interpolated, tck_next, der=2))\n",
    "        denom = np.linalg.norm(dxds,axis=0)**3\n",
    "        wz_values = np.cross(dx2ds2,dxds,axis=0)\n",
    "        #compute curvature\n",
    "        curvature_values = wz_values / denom    \n",
    "        # curvature_values = np.abs(dx2ds2 * dyds - dxds * dy2ds2) / (dxds * dxds + dyds * dyds)**1.5\n",
    "        d_state_next['curvature'] = curvature_values\n",
    "        #record\n",
    "        d_state_curr_lst.append(d_state_curr)\n",
    "        d_state_next_lst.append(d_state_next)\n",
    "    df_state_curr = pd.concat(d_state_curr_lst)\n",
    "    df_state_next = pd.concat(d_state_next_lst)\n",
    "    return df_state_curr,df_state_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754475b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.488858Z",
     "start_time": "2023-03-17T04:32:40.488845Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_local_reference_frame(df_contours, contoursa, contoursa_next, width, height,\n",
    "                                 s=1,per=1,upsampling_rate=4,**kwargs):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "dict_contour_pairs = extract_local_reference_frame(df_contours, contoursa, contoursa_next, width, height)#,s=1,per=1,upsampling_rate=4,**kwargs)\n",
    "    \"\"\"\n",
    "    #for each pair of contours\n",
    "    dict_contour_pairs=dict()\n",
    "    for ci1,row in df_contours.iterrows():\n",
    "        ci2= int(row['ci_next'])\n",
    "        D0 = row['dist_next']\n",
    "        contour1 = contoursa[ci1]\n",
    "        contour2 = contoursa_next[ci2]\n",
    "        #unwind_contour handles pbc\n",
    "        xy_values1 = unwind_contour(contour1,width,height)\n",
    "        xy_values2 = unwind_contour(contour2,width,height)\n",
    "        #^this might be the hard-to-njit rate-limiting step in a faster contour epoch\n",
    "        #compute cublic spline interpolant\n",
    "        tck, s_values = splprep(xy_values1.T,s=s,per=per)\n",
    "        tck_next, s_values_next = splprep(xy_values2.T,s=s,per=per)\n",
    "        s_values_interpolated = np.linspace(0,1,int(np.ceil(s_values.shape[0]*upsampling_rate)))\n",
    "        pts_curr = np.array(splev(s_values_interpolated, tck))\n",
    "        s_values_interpolated = np.linspace(0,1,int(np.ceil(s_values_next.shape[0]*upsampling_rate)))\n",
    "        pts_next = np.array(splev(s_values_interpolated, tck_next))\n",
    "        #compute center of mass\n",
    "        com_curr = np.mean(pts_curr,axis=1)\n",
    "        com_next = np.mean(pts_next,axis=1)\n",
    "        #block unwrap pts_src from pts_dst\n",
    "        xy_shift_unwrap,mindist_unwrap = pbc_robust_shift(com_curr,com_next,width,height) \n",
    "        com_curr_unwrap = (com_curr + xy_shift_unwrap)\n",
    "        displacement = com_next - com_curr_unwrap\n",
    "        #center frames\n",
    "        pts_in = (pts_curr.T+xy_shift_unwrap).T\n",
    "        pts_out = pts_next\n",
    "        xy_shift = com_next - com_curr #+ xy_shift_unwrap)\n",
    "        #record contour information as a learning task\n",
    "        dict_contour_pairs[ci1]=dict(\n",
    "            pts_in=pts_in,\n",
    "            pts_out=pts_out,\n",
    "            tck_in=tck,\n",
    "            tck_out=tck_next,\n",
    "            displacement=displacement,\n",
    "            contour1=contour1,\n",
    "            contour2=contour2,\n",
    "            xy_shift=xy_shift,\n",
    "            xy_shift_unwrap=xy_shift_unwrap,\n",
    "            ci2=ci2,\n",
    "        )\n",
    "    return dict_contour_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19988a1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.490143Z",
     "start_time": "2023-03-17T04:32:40.490131Z"
    }
   },
   "outputs": [],
   "source": [
    "# d_state = bilinear_interpolate_state_lr(x_values,y_values,inVc,dVcdt,vx,vy,inmhjdfx)\n",
    "# inVc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230cefd9",
   "metadata": {},
   "source": [
    "# GOAL: investigate whether there are repeatable forces acting along activation fronts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868833b2",
   "metadata": {},
   "source": [
    "# DONE: generate two sets of contours from which to dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea4156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbd2d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.491515Z",
     "start_time": "2023-03-17T04:32:40.491501Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONE: import example and compute arclen_values\n",
    "#DONE: interpolate txt to contour nodes\n",
    "#DONE: get a sample activation front identified in terms of arcVc_values\n",
    "#DONE: plot curvature versus sigma\n",
    "# - __TODO__: save an activation front curvature values versus time as .csv\n",
    "#TODO: see how ^that evolves with time\n",
    "#TODO(and then...): use ^this method to compute apparent forces from a time series of positions\n",
    "# - ...TODO: come up with some simple rules for curvature versus time\n",
    "# - ...TODO: use intersections to compute interactions between activation fronts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723de3ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:41:12.953774Z",
     "start_time": "2021-05-03T19:41:12.948940Z"
    }
   },
   "source": [
    "Method for smooth numerical curvature\n",
    "1. fitting a BSpline through the data points and \n",
    "1. computing the curvature as a function of derivatives of ^that BSpline fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5245df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.493243Z",
     "start_time": "2023-03-17T04:32:40.493231Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474e2ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.494321Z",
     "start_time": "2023-03-17T04:32:40.494309Z"
    }
   },
   "outputs": [],
   "source": [
    "# #load a mesh from Luo-Rudy\n",
    "# ic_fn=search_for_file()\n",
    "try:\n",
    "    ic_fn=f\"{nb_dir}/Data/initial-conditions-suite-3-LR/ic-out/ic008.33.npz\"\n",
    "    txt=load_buffer(ic_fn)\n",
    "    t=0\n",
    "except FileNotFoundError as e:\n",
    "    ic_fn=f\"{nb_dir}/Data/initial-conditions-suite-3-LR/ic-in/ic008.33.npz\"\n",
    "    txt=load_buffer(ic_fn)\n",
    "    t=0   \n",
    "    \n",
    "save_folder=f\"{nb_dir}/Figures/mov\"    \n",
    "DX=0.025\n",
    "width=txt.shape[0]\n",
    "L = width*DX #cm\n",
    "# ds=5.\n",
    "frameno=0\n",
    "save_every_n_frames=50\n",
    "inVc,outVc,inmhjdfx,outmhjdfx,dVcdt=unstack_txt(txt)\n",
    "width,height=txt.shape[:2]\n",
    "# V_threshold=-50;\n",
    "# V_threshold=-40;\n",
    "V_threshold=-30;\n",
    "\n",
    "dt=0.01\n",
    "dt=0.1\n",
    "# dt=0.5 #unstable\n",
    "\n",
    "# DT=2. #22s\n",
    "# DT=4.  #44s?\n",
    "# DT=4.  #44s?\n",
    "DT=100.  #44s?\n",
    "nsteps_per_DT=int(DT/dt)\n",
    "\n",
    "# comp_dict_topo_full_color=get_comp_dict_topo_full_color(width=width,height=height,level1=V_threshold,level2=0.)\n",
    "# get_one_step at this dt\n",
    "__, arr39, one_step = get_one_step_explicit_synchronous_splitting(\n",
    "    nb_dir,dt=dt,width=width,height=height,ds=L,\n",
    "    diffCoef=0.001,\n",
    "    #diffCoef=0.0005,\n",
    "    Cm=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74133dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.495284Z",
     "start_time": "2023-03-17T04:32:40.495273Z"
    }
   },
   "outputs": [],
   "source": [
    "# comp_dict_topo_simple=get_comp_dict_topo_simple(width=width,height=height,level1=V_threshold,level2=0)\n",
    "# txt=stack_txt(inVc,outVc,inmhjdfx,outmhjdfx,dVcdt)\n",
    "img_prev=txt[...,0].copy()\n",
    "inVc,outVc,inmhjdfx,outmhjdfx,dVcdt=unstack_txt(txt)\n",
    "for n in range(nsteps_per_DT):\n",
    "    one_step(inVc,outVc,inmhjdfx,outmhjdfx,dVcdt)\n",
    "    #t+=dt\n",
    "t+=DT\n",
    "# txt=stack_txt(inVc,outVc,inmhjdfx,outmhjdfx,dVcdt)\n",
    "img=inVc[...,0]\n",
    "dimgdt=dVcdt[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06428eae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.496432Z",
     "start_time": "2023-03-17T04:32:40.496421Z"
    }
   },
   "outputs": [],
   "source": [
    "levela=-30\n",
    "levelb=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a18975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.497365Z",
     "start_time": "2023-03-17T04:32:40.497355Z"
    }
   },
   "outputs": [],
   "source": [
    "imga=img.copy()\n",
    "imgb=dimgdt.copy()\n",
    "#get all xy coordinates of level sets:\n",
    "#HINT: find_contours\n",
    "contoursa = find_contours(array=imga,level=levela,\n",
    "    fully_connected='low',positive_orientation='low',mode='pbc')\n",
    "contoursb = find_contours(array=imgb,level=levelb,\n",
    "    fully_connected='low',positive_orientation='low',mode='pbc')\n",
    "\n",
    "num_contoursa = len(contoursa)\n",
    "num_contoursb = len(contoursa)\n",
    "print(f\"{num_contoursa=}, {num_contoursb=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fc1b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.498665Z",
     "start_time": "2023-03-17T04:32:40.498648Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap='gray'\n",
    "fontsize=12\n",
    "figsize=(12,6)\n",
    "figsize=(8,4)\n",
    "extent=(-L/2,L/2,-L/2,L/2)\n",
    "fig,axs=plt.subplots(ncols=2,figsize=figsize)\n",
    "ax=axs[0]\n",
    "ax.imshow(imga,cmap=cmap,vmin=-50,vmax=10)#,extent=extent)\n",
    "#TODO: overlay level sets for contoursa,b\n",
    "plot_contours_pbc(contoursa, ax, linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color='red')#'blue')\n",
    "\n",
    "ax.tick_params(top=True, right=True,direction='in',which='both')\n",
    "format_plot(ax=ax,fontsize=fontsize,xlabel='',ylabel='')\n",
    "ax=axs[1]\n",
    "ax.imshow(imgb,cmap=cmap,vmin=-30,vmax=30)#,extent=extent)\n",
    "#TODO: overlay level sets for contoursa,b\n",
    "plot_contours_pbc(contoursb, ax, linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color='red')#'blue')\n",
    "\n",
    "ax.tick_params(top=True, right=True,direction='in',which='both')\n",
    "format_plot(ax=ax,fontsize=fontsize,xlabel='',ylabel='')\n",
    "# plt.xticks(rotation=0)#, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd5296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.500273Z",
     "start_time": "2023-03-17T04:32:40.500253Z"
    }
   },
   "outputs": [],
   "source": [
    "# DT=2. #22s\n",
    "# DT=4.  #44s?\n",
    "# DT=4.  #44s?\n",
    "DT=10.  #44s?\n",
    "nsteps_per_DT=int(DT/dt)\n",
    "\n",
    "# comp_dict_topo_simple=get_comp_dict_topo_simple(width=width,height=height,level1=V_threshold,level2=0)\n",
    "# txt=stack_txt(inVc,outVc,inmhjdfx,outmhjdfx,dVcdt)\n",
    "img_prev=txt[...,0].copy()\n",
    "inVc,outVc,inmhjdfx,outmhjdfx,dVcdt=unstack_txt(txt)\n",
    "inVc_curr,outVc_curr,inmhjdfx_curr,outmhjdfx_curr,dVcdt_curr = inVc.copy(),outVc.copy(),inmhjdfx.copy(),outmhjdfx.copy(),dVcdt.copy()\n",
    "for n in range(nsteps_per_DT):\n",
    "    one_step(inVc,outVc,inmhjdfx,outmhjdfx,dVcdt)\n",
    "    #t+=dt\n",
    "t+=DT\n",
    "# txt=stack_txt(inVc,outVc,inmhjdfx,outmhjdfx,dVcdt)\n",
    "img=inVc[...,0]\n",
    "dimgdt=dVcdt[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb276cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.501523Z",
     "start_time": "2023-03-17T04:32:40.501509Z"
    }
   },
   "outputs": [],
   "source": [
    "imga_next=img.copy()\n",
    "imgb_next=dimgdt.copy()\n",
    "inVc_next,outVc_next,inmhjdfx_next,outmhjdfx_next,dVcdt_next = inVc.copy(),outVc.copy(),inmhjdfx.copy(),outmhjdfx.copy(),dVcdt.copy()\n",
    "#get all xy coordinates of level sets:\n",
    "#HINT: find_contours\n",
    "contoursa_next = find_contours(array=imga_next,level=levela,\n",
    "    fully_connected='low',positive_orientation='low',mode='pbc')\n",
    "contoursb_next = find_contours(array=imgb_next,level=levelb,\n",
    "    fully_connected='low',positive_orientation='low',mode='pbc')\n",
    "\n",
    "num_contoursa = len(contoursa)\n",
    "num_contoursb = len(contoursa)\n",
    "print(f\"{num_contoursa=}, {num_contoursb=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263d273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.502813Z",
     "start_time": "2023-03-17T04:32:40.502801Z"
    }
   },
   "outputs": [],
   "source": [
    "# HYPOTHESIS: bosonic holes can account for the attractive force between spiral tips as they annihilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50429d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.503719Z",
     "start_time": "2023-03-17T04:32:40.503708Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_all_spiral_tips= get_compute_all_spiral_tips(mode='simp',width=width,height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3018b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.505074Z",
     "start_time": "2023-03-17T04:32:40.505060Z"
    }
   },
   "outputs": [],
   "source": [
    "#measure system\n",
    "inVc,outVc,inmhjdfx,outmhjdfx,dVcdt=unstack_txt(txt)\n",
    "img=inVc[...,0]#.astype(np.float32)\n",
    "dimgdt=dVcdt[...,0]#.astype(np.float32)\n",
    "# dict_out=compute_all_spiral_tips(t,img,img+dt*dimgdt,level1=V_threshold,level2=V_threshold)#,width=width,height=height)\n",
    "# # t: t=4.000, num tips: 12\n",
    "dict_out=compute_all_spiral_tips(t,img,img+dt*dimgdt,level1=V_threshold,level2=V_threshold)#,width=width,height=height)\n",
    "# t: t=4.000, num tips: 6\n",
    "dict_out['n']=len(dict_out['x'])\n",
    "n = dict_out['n']\n",
    "#print_dict(dict_out)\n",
    "print(f\"t: {t=:.3f}, num tips: {dict_out['n']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529b53c",
   "metadata": {},
   "source": [
    "# compute smoothed splines of contour pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d575b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.506604Z",
     "start_time": "2023-03-17T04:32:40.506589Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap='gray'\n",
    "fontsize=12\n",
    "figsize=(12,6)\n",
    "figsize=(8,4)\n",
    "fig,axs=plt.subplots(ncols=2,figsize=figsize)\n",
    "ax=axs[0]\n",
    "ax.imshow(imga,cmap=cmap,vmin=-50,vmax=10)#,extent=extent)\n",
    "plot_contours_pbc(contoursa, ax, linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color='green')#'blue')\n",
    "ax.tick_params(top=True, right=True,direction='in',which='both')\n",
    "format_plot(ax=ax,fontsize=fontsize,xlabel='',ylabel='')\n",
    "ax=axs[1]\n",
    "ax.imshow(imga_next,cmap=cmap,vmin=-50,vmax=10)#,extent=extent)\n",
    "plot_contours_pbc(contoursa_next, ax, linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color='red')#'blue')\n",
    "ax.tick_params(top=True, right=True,direction='in',which='both')\n",
    "format_plot(ax=ax,fontsize=fontsize,xlabel='',ylabel='')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1021321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.508074Z",
     "start_time": "2023-03-17T04:32:40.508055Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute discrete -grad(dVdt) vector field\n",
    "# imgb=dimgdt\n",
    "# imgb_next=dimgdt\n",
    "ddVdtdx=np.gradient(imgb,axis=0)/DX #not stable in time\n",
    "ddVdtdy=-np.gradient(imgb,axis=1)/DX #not stable in time\n",
    "vx=ddVdtdx\n",
    "vy=ddVdtdy\n",
    "ddVdtdx=np.gradient(imgb_next,axis=0)/DX #not stable in time\n",
    "ddVdtdy=-np.gradient(imgb_next,axis=1)/DX #not stable in time\n",
    "vx_next=ddVdtdx\n",
    "vy_next=ddVdtdy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d00bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.509401Z",
     "start_time": "2023-03-17T04:32:40.509389Z"
    }
   },
   "outputs": [],
   "source": [
    "# dict2d = dict(inVc=inVc,dVcdt=dVcdt,vx=vx,vy=vy,inmhjdfx=inmhjdfx)\n",
    "dict2d_curr = dict(inVc=inVc_curr,dVcdt=dVcdt_curr,vx=vx,vy=vx,inmhjdfx=inmhjdfx_curr)\n",
    "dict2d_next = dict(inVc=inVc_next,dVcdt=dVcdt_next,vx=vx_next,vy=vy_next,inmhjdfx=inmhjdfx_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b1e2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.511353Z",
     "start_time": "2023-03-17T04:32:40.511341Z"
    }
   },
   "outputs": [],
   "source": [
    "d_state_lst=[]\n",
    "for i,contour in enumerate(contoursa):\n",
    "    #contour nodes are chosen on the edges between sites\n",
    "    x_values = contour[:,0]\n",
    "    y_values = contour[:,1]\n",
    "    # bilinear_interpolate image to sites\n",
    "    # states_txt = interpolate_img(x_values,y_values,width,height,txt)\n",
    "    states_inVc = np.array(interpolate_img(x_values,y_values,width,height,inVc))\n",
    "    states_dVcdt = np.array(interpolate_img(x_values,y_values,width,height,dVcdt))\n",
    "    states_vx = np.array(interpolate_img(x_values,y_values,width,height,vx))\n",
    "    states_vy = np.array(interpolate_img(x_values,y_values,width,height,vy))\n",
    "    states_inmhjdfx = np.array(interpolate_img(x_values,y_values,width,height,inmhjdfx))\n",
    "    d_state = pd.DataFrame(dict(X=x_values,Y=y_values,\n",
    "                                  V=states_inVc[:,0],Ca=states_inVc[:,1],\n",
    "                                  dVdt= states_dVcdt[:,0],dCadt= states_dVcdt[:,1],\n",
    "                                  vX= states_vx,vY= states_vy,\n",
    "                                  m= states_inmhjdfx[:,0],h= states_inmhjdfx[:,1],\n",
    "                                  j= states_inmhjdfx[:,2],d= states_inmhjdfx[:,3],\n",
    "                                  f= states_inmhjdfx[:,4],x= states_inmhjdfx[:,5],\n",
    "                                 ))\n",
    "    d_state['cid']=i\n",
    "    d_state_lst.append(d_state)\n",
    "df_state = pd.concat(d_state_lst)\n",
    "df_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ace93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.512586Z",
     "start_time": "2023-03-17T04:32:40.512573Z"
    }
   },
   "outputs": [],
   "source": [
    "df_state.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a4842",
   "metadata": {},
   "source": [
    "# TODO: use the Chamfer distance to find contour pairs between the two frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c4069",
   "metadata": {},
   "source": [
    "$D_{ij}^{(Chamfer)} = \\sum_{x_i \\in x}{\\min_{y_j \\in y}{||x_i-y_j||^2}} + \\sum_{y_j \\in y}{\\min_{x_i \\in x}{||x_i-y_j||^2}}$\n",
    "\n",
    "Denote the mean curvature of contour i=x as $\\bar H(X_i)$ with mean stiffness $\\bar\\lambda_i = \\lambda(k_i(t))$.\n",
    "\n",
    "Denote the mean tension as $\\bar\\tau_i$ for the $i^{th}$ contour with arclength, $L_i=(\\Phi_{\\Delta t}(X_i))$\n",
    "\n",
    "$Loss = \\sum_{ij\\in P_{airs}} D_{ij}^{(Chamfer)} + \\sum_{i}\\bar\\lambda_i H(\\Phi_{\\Delta t}(X_i)) - \\sum_{i}\\bar\\tau_i L_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f59a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.513940Z",
     "start_time": "2023-03-17T04:32:40.513924Z"
    }
   },
   "outputs": [],
   "source": [
    "num1 = len(contoursa)\n",
    "num2 = len(contoursa_next)\n",
    "maxdist=width*height\n",
    "ci2_neighbor_lst=[]\n",
    "dist_lst=[]\n",
    "for ci1 in range(num1):\n",
    "    dist=maxdist\n",
    "    for ci2 in range(num2):\n",
    "        dist_chamfer = chamfer_distance(contoursa[ci1], contoursa_next[ci2], metric='l2', direction='bi')\n",
    "        if dist_chamfer<dist:\n",
    "            dist=dist_chamfer\n",
    "            ci2_neighbor = ci2\n",
    "    #record\n",
    "    ci2_neighbor_lst.append(ci2_neighbor)\n",
    "    dist_lst.append(dist)\n",
    "df_contours = pd.DataFrame(dict(\n",
    "    ci_next=ci2_neighbor_lst,\n",
    "    dist_next=dist_lst\n",
    "))\n",
    "# df_contours\n",
    "\n",
    "#filter any contours that disappear\n",
    "df_contours = df_contours.sort_values(by='dist_next').groupby(by='ci_next').head(1)\n",
    "print(f\"{num1=}, {num2=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db639e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.515692Z",
     "start_time": "2023-03-17T04:32:40.515678Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualize the pairings\n",
    "cmap='gray'\n",
    "fontsize=12\n",
    "figsize=(12,6)\n",
    "figsize=(4,4)\n",
    "fig,ax=plt.subplots(figsize=figsize)\n",
    "# ax=axs[0]\n",
    "ax.imshow(imga,cmap=cmap,vmin=-50,vmax=10)#,extent=extent)\n",
    "# ax.imshow(imga_next,cmap=cmap,vmin=-50,vmax=10)#,extent=extent)\n",
    "plot_contours_pbc(contoursa, ax, linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color='green')#'blue')\n",
    "plot_contours_pbc(contoursa_next, ax, linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color='red')#'blue')\n",
    "ax.tick_params(top=True, right=True,direction='in',which='both')\n",
    "format_plot(ax=ax,fontsize=fontsize,xlabel='',ylabel='')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07790f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.516732Z",
     "start_time": "2023-03-17T04:32:40.516719Z"
    }
   },
   "outputs": [],
   "source": [
    "# # plot_contours_pbc(contoursa, plt.gca(), linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color='green')#'blue')\n",
    "# plot_contours_pbc([contoursa[0]], plt.gca(), linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color='green')#'blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17656498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.517872Z",
     "start_time": "2023-03-17T04:32:40.517861Z"
    }
   },
   "outputs": [],
   "source": [
    "len(contoursa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43754e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.519041Z",
     "start_time": "2023-03-17T04:32:40.519027Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualize the pairings\n",
    "cmap='gray'\n",
    "fontsize=12\n",
    "figsize=(12,6)\n",
    "figsize=(4,4)\n",
    "fig,ax=plt.subplots(figsize=figsize)\n",
    "# ax=axs[0]\n",
    "ax.imshow(imga,cmap=cmap,vmin=-50,vmax=10)#,extent=extent)\n",
    "# ax.imshow(imga_next,cmap=cmap,vmin=-50,vmax=10)#,extent=extent)\n",
    "# #for each pair of contours\n",
    "for ci1,row in df_contours.iterrows():\n",
    "    ci2= int(row['ci_next'])\n",
    "    D0 = row['dist_next']\n",
    "    contour1 = contoursa[ci1]\n",
    "    contour2 = contoursa_next[ci2]\n",
    "    plot_contours_pbc([contour1], ax=ax, linewidth=3, min_num_vertices=6, linestyle='--', alpha=0.5, color=f'C{ci1}')#'blue')\n",
    "    plot_contours_pbc([contour2], ax=ax, linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color=f'C{ci1}')#'blue')\n",
    "#     plot_contours_pbc([contour1[0]], ax=ax, linewidth=3, min_num_vertices=6, linestyle='-', alpha=0.5, color=f'C{ci1}')#'blue')\n",
    "#     plot_contours_pbc([contour2[0]], ax=ax, linewidth=3, min_num_vertices=6, linestyle=':', alpha=0.5, color=f'C{ci1}')#'blue')\n",
    "# ax.tick_params(top=True, right=True,direction='in',which='both')\n",
    "# format_plot(ax=ax,fontsize=fontsize,xlabel='',ylabel='')\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf70175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.520280Z",
     "start_time": "2023-03-17T04:32:40.520267Z"
    }
   },
   "outputs": [],
   "source": [
    "for ci1,row in df_contours.iterrows():\n",
    "    ci2= int(row['ci_next'])\n",
    "    D0 = row['dist_next']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4193b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.521465Z",
     "start_time": "2023-03-17T04:32:40.521452Z"
    }
   },
   "outputs": [],
   "source": [
    "#heretimheretim\n",
    "#TODO: verify the curves are paired correctly\n",
    "#TODO: develop a simple way to map pairs of curve onto one another\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36fe7c",
   "metadata": {},
   "source": [
    "# compute spline interpolants of either contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43dedd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.522762Z",
     "start_time": "2023-03-17T04:32:40.522750Z"
    }
   },
   "outputs": [],
   "source": [
    "upsampling_rate=4\n",
    "per=1 #use periodic boundary conditions\n",
    "s=1 #enough smoothing to remove the subpixel wiggles\n",
    "# s=0 #no smoothing\n",
    "# s=5 #too much smoothing\n",
    "dict_contour_pairs = extract_local_reference_frame(df_contours, contoursa, contoursa_next, width, height)#,s=1,per=1,upsampling_rate=4,**kwargs)\n",
    "df_state_curr,df_state_next = extract_curvilinear_states_lr(df_contours, contoursa, contoursa_next, vx, vy, inVc, dVcdt, inmhjdfx)#,s=1,per=1,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd04ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.524127Z",
     "start_time": "2023-03-17T04:32:40.524115Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_mean_states=dict()\n",
    "#for each pair of contours\n",
    "for ci1,row in df_contours.iterrows():\n",
    "    ci2= int(row['ci_next'])\n",
    "    D0 = row['dist_next'] \n",
    "    contour1 = contoursa[ci1]\n",
    "    contour2 = contoursa_next[ci2]\n",
    "    #unwind_contour handles pbc\n",
    "    xy_values1 = unwind_contour(contour1,width,height)\n",
    "    xy_values2 = unwind_contour(contour2,width,height)\n",
    "    #^this might be the hard-to-njit rate-limiting step in a faster contour epoch\n",
    "    #compute cublic spline interpolant\n",
    "    tck, s_values = splprep(xy_values1.T,s=s,per=per)\n",
    "    tck_next, s_values_next = splprep(xy_values2.T,s=s,per=per)\n",
    "    s_values_interpolated = np.linspace(0,1,int(np.ceil(s_values.shape[0]*upsampling_rate)))\n",
    "    pts_curr = np.array(splev(s_values_interpolated, tck))\n",
    "    pts_next = np.array(splev(s_values_interpolated, tck_next))\n",
    "    #compute linearly interpolated contour positions and curvature\n",
    "    #measure the size and shape of either contour\n",
    "    dxds = np.array(splev(s_values_interpolated, tck, der=1))\n",
    "    dx2ds2 = np.array(splev(s_values_interpolated, tck, der=2))\n",
    "    denom = np.linalg.norm(dxds,axis=0)**3\n",
    "    wz_values = np.cross(dx2ds2,dxds,axis=0)\n",
    "    # wz_values = np.cross(dxds,dx2ds2,axis=0)\n",
    "    #Q: which of ^these has the \"right\" sign?\n",
    "    curvature_values = wz_values / denom\n",
    "    # curvature_values = np.abs(dx2ds2 * dyds - dxds * dy2ds2) / (dxds * dxds + dyds * dyds)**1.5\n",
    "    # return curvature_values,new_points,dxds,dx2ds2\n",
    "    # new_points,curvature_values,dxds,dx2ds2 = comp_contour_curvature(contour)\n",
    "    #compute the average curvature measures\n",
    "    H0 = np.mean(curvature_values)    \n",
    "    rhomax = np.max(curvature_values)/2\n",
    "    rhomin = np.min(curvature_values)/2\n",
    "    #compute the overall length\n",
    "    arclen = np.linalg.norm(np.diff(new_points),axis=0).sum()\n",
    "    #record\n",
    "    df_contours.loc[ci1,'mncurv']=H0\n",
    "    df_contours.loc[ci1,'arclen']=arclen\n",
    "    df_contours.loc[ci1,'rhomin']=rhomin\n",
    "    df_contours.loc[ci1,'rhomax']=rhomax\n",
    "    #get the interpolated values\n",
    "    dict_mean_state_curr = df_state_curr.loc[df_state_curr['cid']==ci1].mean().to_dict()\n",
    "    dict_mean_state_next = df_state_next.loc[df_state_next['cid']==ci2].mean().to_dict()\n",
    "    #record\n",
    "    dict_mean_states[ci1] = dict(dict_mean_state_curr=dict_mean_state_curr,\n",
    "                             dict_mean_state_next=dict_mean_state_next)\n",
    "    df_contours.loc[ci1,'V_curr']=dict_mean_state_curr['V']\n",
    "    df_contours.loc[ci1,'dVdt_curr']=dict_mean_state_curr['dVdt']\n",
    "    df_contours.loc[ci1,'V_next']=dict_mean_state_next['V']\n",
    "    df_contours.loc[ci1,'dVdt_next']=dict_mean_state_next['dVdt']\n",
    "df_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c9999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.525164Z",
     "start_time": "2023-03-17T04:32:40.525153Z"
    }
   },
   "outputs": [],
   "source": [
    "df_contours,\n",
    "df_state_curr,\n",
    "df_state_next,\n",
    "dict_contour_pairs,\n",
    "dict_mean_state_curr,\n",
    "dict_mean_state_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1b870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.526373Z",
     "start_time": "2023-03-17T04:32:40.526360Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_mean_state_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3f8d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.527784Z",
     "start_time": "2023-03-17T04:32:40.527750Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.linalg.norm(dxds,axis=1)\n",
    "# new_points[:,0],new_points[:,-1]\n",
    "data = dict(t=t,\n",
    "            model='Luo-Rudy',\n",
    "            dict_tips=dict_out,\n",
    "            ic_fn=ic_fn,\n",
    "            df_contours=df_contours,\n",
    "            dict_contour_pairs=dict_contour_pairs,\n",
    "            df_state_curr=df_state_curr,\n",
    "            df_state_next=df_state_next,\n",
    "            dict_mean_state_curr=dict_mean_state_curr,\n",
    "            dict_mean_state_next=dict_mean_state_next,\n",
    "    dict1d = dict(contoursa=contoursa,\n",
    "                    contoursa_next=contoursa_next,\n",
    "                    contoursb=contoursb,\n",
    "                    contoursb_next=contoursb_next,\n",
    "                    levela=levela,levelb=levelb),\n",
    "    dict2d = dict(img=imga,\n",
    "            img_next=imga_next,\n",
    "            current_fields = dict2d_curr,\n",
    "            next_fields = dict2d_next),\n",
    ")\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211834c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.529204Z",
     "start_time": "2023-03-17T04:32:40.529190Z"
    }
   },
   "outputs": [],
   "source": [
    "#save the data\n",
    "data_folder = '/'.join(ic_fn.split('/')[:-2])+'/contour_data'\n",
    "if not os.path.exists(data_folder):\n",
    "    os.mkdir(data_folder)\n",
    "data_fn = ic_fn.split('/')[-1].replace('.npz',f'_contours_t_{int(t)}.pkl')#.replace('ic','contours')\n",
    "data_dir = os.path.join(data_folder,data_fn)\n",
    "save_to_pickle(data_dir,data)\n",
    "print(f\"{data_dir=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a56a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.530437Z",
     "start_time": "2023-03-17T04:32:40.530424Z"
    }
   },
   "outputs": [],
   "source": [
    "# !open /Users/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/contour_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33b7da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.531792Z",
     "start_time": "2023-03-17T04:32:40.531780Z"
    }
   },
   "outputs": [],
   "source": [
    "#input: a learning task (xy before/after)\n",
    "#output: minimum chanfer distance contour deformation\n",
    "#HINT: i think pytorch3d has a function optimized for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708cfbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.533504Z",
     "start_time": "2023-03-17T04:32:40.533487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Q: can i reduce it to slerp interpolating two curves in 2D (embedded in 3D)?\n",
    "# A: yes AFTER I find a closest point on the target mesh.  \n",
    "#  ^ this requires preprocessing with some kind of chanfer solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175934c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.535148Z",
     "start_time": "2023-03-17T04:32:40.535134Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{com_curr=},\\n{com_next=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3a527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.536648Z",
     "start_time": "2023-03-17T04:32:40.536635Z"
    }
   },
   "outputs": [],
   "source": [
    "#xy_shift_unwrap is the shift from periodic bc's only!\n",
    "#block unwrap pts_src from pts_dst\n",
    "xy_shift_unwrap,mindist_unwrap = pbc_robust_shift(com_curr,com_next,width,height) \n",
    "com_curr_unwrap = (com_curr + xy_shift_unwrap)\n",
    "#compute xy_shift to center the two shapes\n",
    "# xy_shift = com_curr_unwrap - com_next\n",
    "displacement = com_next - com_curr_unwrap\n",
    "# print(f\"{com_curr=},\\n{com_curr+xy_shift=},\\n{com_next=}\")\n",
    "# print(f\"{xy_shift=},\\n{xy_shift_unwrap=}\")\n",
    "# print(f\"{com_curr+xy_shift_unwrap=},\\n{com_next=}\\n{displacement=}\")\n",
    "print(f\"{com_next - (com_curr+xy_shift_unwrap) =}\\n{displacement=}\")\n",
    "#they agree, it seems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f3677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.538030Z",
     "start_time": "2023-03-17T04:32:40.538017Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=figsize)\n",
    "# plt.quiver([com_curr_unwrap[0]],[com_curr_unwrap[1]],[displacement[0]],[displacement[1]],\n",
    "#         lw=4,color='k',alpha=0.7,units='xy')\n",
    "ax.scatter([com_curr_unwrap[0],com_curr_unwrap[0]+displacement[0]],\n",
    "            [com_curr_unwrap[1],com_curr_unwrap[1]]+displacement[1],\n",
    "        lw=4,color='k',alpha=0.7)#,units='xy')\n",
    "ax.plot([com_curr_unwrap[0],com_curr_unwrap[0]+displacement[0]],\n",
    "            [com_curr_unwrap[1],com_curr_unwrap[1]]+displacement[1],\n",
    "        lw=4,color='k',alpha=0.7)#,units='xy')\n",
    "ax.scatter(x=pts_curr[0]+xy_shift[0],y=pts_curr[1]+xy_shift[1],color='g',alpha=0.7)\n",
    "ax.scatter(x=pts_next[0],y=pts_next[1],color='r',alpha=0.7)\n",
    "format_plot(ax=ax,fontsize=fontsize,xlabel='X  (pxls)',ylabel='Y  (pxls)')\n",
    "ax.tick_params(top=True, right=True,direction='in',which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055232d4",
   "metadata": {},
   "source": [
    "# TODO: caste this into a point cloud deformation problem and then try to solve it efficiently in pytorch3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0016ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T01:34:16.620034Z",
     "start_time": "2023-03-16T01:34:16.531620Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f32b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad607f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf364c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e461f6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.539513Z",
     "start_time": "2023-03-17T04:32:40.539502Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# # from pytorch3d.io import load_obj, save_obj\n",
    "# ! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da532b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.540595Z",
     "start_time": "2023-03-17T04:32:40.540582Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install torch-points3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9fba2",
   "metadata": {},
   "source": [
    "# don't expect good results getting the minimal displacements with simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7bb9dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.541708Z",
     "start_time": "2023-03-17T04:32:40.541696Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed=42\n",
    "# # scipy.optimize.minimize(mindist, )\n",
    "# #TODO: recall latest dual simulated annealing solver\n",
    "# #TODO: cp it here\n",
    "# #TOOD: modify it to find the s that minimizes the distance between pt0_src and pts_dst\n",
    "# pts_src = xy_values1 + xy_shift\n",
    "# tck_dst = tck_next\n",
    "# for pt0_src in pts_src:\n",
    "#     args = (pt0_src,tck_dst)\n",
    "#     bounds = [(-0.01,1.01),]\n",
    "# res = dual_annealing(\n",
    "#     comp_distance_to_spline,\n",
    "#     bounds=bounds,\n",
    "#     args=args,\n",
    "#     maxiter=10000,\n",
    "# #     local_search_options={},\n",
    "# #     initial_temp=5.0,\n",
    "# #     initial_temp=5230.0,\n",
    "# #     restart_temp_ratio=2e-05,\n",
    "# #     visit=2.62,\n",
    "# #     accept=-5.0,\n",
    "# #     maxfun=10000000.0,\n",
    "# #     seed=seed,\n",
    "#     no_local_search=True,\n",
    "# #     callback=None,\n",
    "# #     x0=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80193661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.543297Z",
     "start_time": "2023-03-17T04:32:40.543273Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(f\"{s}: {comp_distance_to_spline(s,*args)=}\")\n",
    "# print(f\"{res.x[0]}: {comp_distance_to_spline(res.x,*args)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9b623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.544288Z",
     "start_time": "2023-03-17T04:32:40.544271Z"
    }
   },
   "outputs": [],
   "source": [
    "# xv = np.linspace(-0.1,1.1,100)\n",
    "# yv = np.array([comp_msdistance_to_spline(x,*args) for x in xv])\n",
    "# plt.plot(xv,yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f9489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.545571Z",
     "start_time": "2023-03-17T04:32:40.545557Z"
    }
   },
   "outputs": [],
   "source": [
    "# dual_annealing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3de8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.547116Z",
     "start_time": "2023-03-17T04:32:40.547103Z"
    }
   },
   "outputs": [],
   "source": [
    "# # curvature_values = np.abs(dx2ds2 * dyds - dxds * dy2ds2) / (dxds * dxds + dyds * dyds)**1.5\n",
    "# # return curvature_values\n",
    "# plt.plot(xy_values[:,0],xy_values[:,1])#,c=curvature_values,cmap='gray_r')\n",
    "# plt.plot(new_points[0],new_points[1])#,c=curvature_values,cmap='gray_r')\n",
    "# plt.scatter(x=new_points[0],y=new_points[1],c=curvature_values,cmap='gray_r')\n",
    "# # new_points.shape\n",
    "# # TODO(later): determine the maximum curvature location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f9d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.548817Z",
     "start_time": "2023-03-17T04:32:40.548798Z"
    }
   },
   "outputs": [],
   "source": [
    "#potential first integrals:\n",
    "#mean curvature (a topological invariant here?)\n",
    "#tensile energy (requires notion of mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83425ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76415834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.550001Z",
     "start_time": "2023-03-17T04:32:40.549986Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_chamfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7df5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b5f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.551513Z",
     "start_time": "2023-03-17T04:32:40.551498Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: place -grad(dVdt) quiver at each node of contoursa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837a2ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.552806Z",
     "start_time": "2023-03-17T04:32:40.552776Z"
    }
   },
   "outputs": [],
   "source": [
    "#fastest way to do this:\n",
    "#general bilinear interpolation on the square\n",
    "#provably exact using only 3 pixels\n",
    "#HINT: search bilinear from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0edcde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.553867Z",
     "start_time": "2023-03-17T04:32:40.553854Z"
    }
   },
   "outputs": [],
   "source": [
    "# DONE: map these guys to pandas.DataFrame \n",
    "# inVc,dVcdt,inmhjdfx,vx,vy,x,y,cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc731a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83196bdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.555527Z",
     "start_time": "2023-03-17T04:32:40.555510Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.floor(contour[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bc459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc8f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.557141Z",
     "start_time": "2023-03-17T04:32:40.557125Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONE(later): smooth dimgdt slightly and detect contours on its bumpy surface\n",
    "#DONE: overlay contoursa\n",
    "#TODO: estimate the time-like tangent space of contoursa along the curve\n",
    "#TODO: visualize the dual states with a quiver plot\n",
    "#TODO: dev function that smoothly interpolates nodes from initial dual state to final dual state \n",
    "#HINT: what function smoothly interpolates from step to step+1 that\n",
    "#  1. minimizes the distance between each node and the interpolated curve at step+1\n",
    "#  2. minimizes the change in distance between two nodes\n",
    "#HINT: as DT-->0, contoursa must move in the direction of -grad(dVdt)\n",
    "#HYPOTHESIS: the local texture properties govern the instantaneous change in curvature of activation fronts\n",
    "#CLAIM: if we can predict the time evolution of the kymograph of local properties, \n",
    "#    then we can predict the direction of -grad(dVdt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b8b12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.558343Z",
     "start_time": "2023-03-17T04:32:40.558331Z"
    }
   },
   "outputs": [],
   "source": [
    "#GOAL: estimate spiral tip locations using only the local properties of contoursa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48286ce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.559356Z",
     "start_time": "2023-03-17T04:32:40.559345Z"
    }
   },
   "outputs": [],
   "source": [
    "# ax.quiver(x, y, z, us, vs, ws, length=1, normalize=False, color='orange', label='spring forces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159051a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.560484Z",
     "start_time": "2023-03-17T04:32:40.560472Z"
    }
   },
   "outputs": [],
   "source": [
    "# xy_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60b1c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.561754Z",
     "start_time": "2023-03-17T04:32:40.561741Z"
    }
   },
   "outputs": [],
   "source": [
    "# #TODO: estimate the space-like tangent space of contoursa along the curve\n",
    "# xy_values = contour\n",
    "# new_points=comp_interpolated_points(xy_values,s=1)\n",
    "# curvature_values=comp_curvature(xy_values)/DX\n",
    "# sigma_unitless_values=np.linspace(0,1,curvature_values.shape[0])\n",
    "# sigma_values=arclen*sigma_unitless_values\n",
    "# c_values=curvature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c2862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.563821Z",
     "start_time": "2023-03-17T04:32:40.563804Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Q: does comp_curvature respect pbc?\n",
    "# comp_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17758a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17102f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.565711Z",
     "start_time": "2023-03-17T04:32:40.565696Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO(later): determine the maximum curvature location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b71a5",
   "metadata": {},
   "source": [
    "# developing activation front kymographs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5f44f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T04:32:40.566819Z",
     "start_time": "2023-03-17T04:32:40.566808Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: dev of activation front kymographs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321db5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb291d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
