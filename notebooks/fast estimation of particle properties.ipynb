{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bceb72",
   "metadata": {},
   "source": [
    "# fast estimation of particle properties\n",
    "Tim Tyree<br>\n",
    "9.29.2021<br>\n",
    "`conda activate pyenv_ub`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bdb43b",
   "metadata": {},
   "source": [
    "__TODO(later):__ bug mike to make certain that for the 99.95% accurate decoder, that the i^th neuron for the Match trials is the same as the i^th neuron for the Mismatch trials for all i neuron-units considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aed5ab",
   "metadata": {},
   "source": [
    "__TODO__: use more smoothing than just tavg1=2 or 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a420553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T03:40:18.986940Z",
     "start_time": "2021-09-30T03:40:18.955224Z"
    }
   },
   "source": [
    "__GOAL__: efficiently generate an inline rendering of dRdt versus 1/R and MSD versus tau using dashly.  try the solution suggested on my stackoverflow post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c811d0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.510197Z",
     "start_time": "2021-10-02T21:31:16.395582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic calling is: Smart\n"
     ]
    }
   ],
   "source": [
    "from lib.my_initialization import *\n",
    "from lib import *\n",
    "# from lib.measure.unwrap_and_smooth_cu import *\n",
    "# from lib.rapids_func import *\n",
    "# .routines.unwrap_and_smooth_trajectories_cu import *\n",
    "\n",
    "import itertools\n",
    "import dask_cudf\n",
    "from lib.rapids_func import *\n",
    "get_DT_cu\n",
    "\n",
    "#magic    \n",
    "%autocall 1\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cupy as cp, cudf, numba.cuda as cuda\n",
    "import rmm\n",
    "# Switch to RMM allocator\n",
    "cp.cuda.set_allocator(rmm.rmm_cupy_allocator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b8882d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.608821Z",
     "start_time": "2021-10-02T21:31:18.512354Z"
    }
   },
   "outputs": [],
   "source": [
    "darkmode=True\n",
    "if darkmode:\n",
    "    # For darkmode plots\n",
    "    from jupyterthemes import jtplot\n",
    "    jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6fce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T07:44:21.858663Z",
     "start_time": "2021-09-30T07:44:21.823646Z"
    }
   },
   "source": [
    "# (optional) postprocess a token trajectory file\n",
    "- Nota Bene: batch computation is already automated and optimized in 'fast postprocessing a list of trajectory folders.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c062e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.646220Z",
     "start_time": "2021-10-02T21:31:18.611341Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_fn=search_for_file()\n",
    "\n",
    "# # #token FK at DT=0.4\n",
    "# input_fn=\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-fk-200x200/param_set_8_ds_5.0_tmax_10_diffCoef_0.0005/Log/ic200x200.0.2_traj_sr_400_mem_0.csv\"\n",
    "\n",
    "# # #tokenLR at DT=0.5\n",
    "# input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.5/trajectories/ic002.31_traj_sr_600_mem_0.csv\"\n",
    "input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.5/trajectories/ic002.11_traj_sr_600_mem_0.csv\"\n",
    "\n",
    "#test routine on one file\n",
    "testing=False\n",
    "if testing:\n",
    "    df=pd.read_csv(input_fn)\n",
    "    DT=np.around(get_DT(df),5);print(f\"DT={DT}\")\n",
    "    # ds=5 #cm\n",
    "    # DS=ds/width\n",
    "    tavg1=4 #moving average window, in ms\n",
    "    width=200\n",
    "    height=width\n",
    "    use_drop_shorter_than=True\n",
    "    drop_shorter_than=50 #ms\n",
    "    tmin=100.#ms\n",
    "    pid_col='particle'\n",
    "    t_col='t'\n",
    "    printing=False\n",
    "    navg1=int(tavg1/DT)\n",
    "    save_dir=return_moving_average_of_pbc_trajectories_and_save(\n",
    "            input_fn, tavg1, pid_col, t_col, DT, width, height,\n",
    "            use_drop_shorter_than, drop_shorter_than, tmin, printing)\n",
    "    print(save_dir)\n",
    "\n",
    "    df=load_smoothed_trajectories(save_dir,pid_col,t_col)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8926afa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.669362Z",
     "start_time": "2021-10-02T21:31:18.647491Z"
    }
   },
   "outputs": [],
   "source": [
    "#run the routine on a whole folder\n",
    "# print((DT, input_fn))\n",
    "# save_dir_lst=routine_postprocess_trajectory_folder(input_fn,DT,tavg1=4, npartitions=None,\n",
    "#                                         width=200,\n",
    "#                                         height=200,\n",
    "#                                         use_drop_shorter_than=True,\n",
    "#                                         drop_shorter_than=50, #ms\n",
    "#                                         tmin=100., #ms\n",
    "#                                         pid_col='particle',\n",
    "#                                         t_col='t',\n",
    "#                                         printing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b837b31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.691418Z",
     "start_time": "2021-10-02T21:31:18.670634Z"
    }
   },
   "outputs": [],
   "source": [
    "# #TODO(later): compute squared displacements\n",
    "# grouped=df.groupby(pid_col)\n",
    "# #HINT: squared displacements of particles is result\n",
    "#  throws AttributeError: DataFrameGroupBy object has no attribute first \n",
    "# result = (grouped[['x','y']]-grouped[['x','y']].first())**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791ed272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.713531Z",
     "start_time": "2021-10-02T21:31:18.692777Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO(later): implement a one_step method on an element in a finite element simulation\n",
    "# HINT: cudf.Grouper?\n",
    "# HINT: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#grouping-with-a-grouper-specification\n",
    "# HINT: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cadd81b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.733775Z",
     "start_time": "2021-10-02T21:31:18.714942Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONE: figure out if there's an elegant was to use the cudf api  to do this\n",
    "#for each group of event_id_int's :\n",
    "#compare every particle to every other particle in a simple way\n",
    "#compare every particle to every other particle to determine if the self,other pair intersects nontrivially\n",
    "\n",
    "#DONE: determine condition for whether each pair is intersecting for at least two times \n",
    "# two particles exist for at least two times if both\n",
    "#if other has a tmin > tmin of self\n",
    "#AND if other has a tmax < tmax of self, \n",
    "\n",
    "# #DONE: construct the graph of all edges... this wasn't useful...\n",
    "# G = cugraph.Graph()\n",
    "# G.from_cudf_edgelist(df_pairs, source='src', destination='dst', edge_attr='dst')\n",
    "# # # Let's now get the PageRank score of each vertex by calling cugraph.pagerank\n",
    "# # df_page = cugraph.pagerank(G)\n",
    "# # df_page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "486494a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.753656Z",
     "start_time": "2021-10-02T21:31:18.734946Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONE: compute which edges are intersecting\n",
    "#DONE: compute tmin and tmax for each intersecting edge\n",
    "#DONE: compute duration for each intersecting edge\n",
    "#DONE: sort edges by duration\n",
    "#DONE: visualize the histogram of durations of intersecting edges\n",
    "#DONE: consider a minimum_duration_threshold that is at least tavg2 if not specified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d1e9d",
   "metadata": {},
   "source": [
    "## scratchwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "898392ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.774799Z",
     "start_time": "2021-10-02T21:31:18.755875Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONT: figure out terrible numba debugging for a negligible speed boost\n",
    "# @cuda.jit()#device=True)\n",
    "# def distance_L2_pbc_cuda(point_1, point_2, dist_out, shape):\n",
    "#     '''distance_L2_pbc_cu is a jit compiled function that \n",
    "#     returns for the euclidean (L2) distance between \n",
    "#     point_1 and point_2, which are in an N-cube of shape shape \n",
    "#     with periodic boundary conditions\n",
    "    \n",
    "#     Example Usage:\n",
    "#     blockspergrid=1\n",
    "#     threadsperblock=1\n",
    "#     point_1=self_values[0]\n",
    "#     point_2=other_values[0]\n",
    "#     dist_out=0.#overwritten\n",
    "#     shape=(width,height)\n",
    "#     distance_L2_pbc_cuda[blockspergrid, threadsperblock](point_1, point_2, dist_out, shape)\n",
    "#     '''\n",
    "#     dq2 = 0.\n",
    "#     for q1, q2, wid in zip(point_1, point_2, shape):\n",
    "#         dq2 = dq2 + min(((q2 - q1)**2, (q2 + wid - q1 )**2, (q2 - wid - q1 )**2))\n",
    "#     dist_out= dq2**0.5\n",
    "\n",
    "# blockspergrid=1\n",
    "# threadsperblock=1\n",
    "# point_1=self_values[0]\n",
    "# point_2=other_values[0]\n",
    "# dist_out=np.array([0.])#*self_values\n",
    "# shape=(width,height)\n",
    "# # distance_L2_pbc_cuda(point_1, point_2, dist_out, shape)\n",
    "# distance_L2_pbc_cuda[blockspergrid, threadsperblock](point_1, point_2, dist_out, shape)\n",
    "# dist_out, point_1, point_2\n",
    "\n",
    "# from numba import vectorize\n",
    "# # shape=(width,height)\n",
    "# # @vectorize(['float32[:](float32, float32, float32)'], target='cuda')\n",
    "# shape=cp.array((width,height))\n",
    "# @vectorize(['(float32[:,:], float32[:,:], float32[:,:], float32[:])'], target='cuda')\n",
    "# def distance_L2_pbc_cu(self_values, other_values, dist_out_values, shape):\n",
    "#     for point_1, point_2, dist_out in zip(self_values, other_values, dist_out_values):\n",
    "#         distance_L2_pbc_cuda(point_1, point_2, dist_out, shape)\n",
    "\n",
    "# # blockspergrid=1\n",
    "# # threadsperblock=1\n",
    "# dist_out_values=0.*self_values\n",
    "# shape=cp.array((width,height))\n",
    "# distance_L2_pbc_cu(self_values, other_values, dist_out_values, shape)\n",
    "# # distance_L2_pbc_cuda[blockspergrid, threadsperblock](point_1, point_2, dist_out, shape)\n",
    "# # dist_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffae6abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.795298Z",
     "start_time": "2021-10-02T21:31:18.775818Z"
    }
   },
   "outputs": [],
   "source": [
    "# def extract_xy_values_of_pair(df,pair,t_col='t'):\n",
    "#     '''\n",
    "#     df is a cudf.DataFrame instance of xy trajectories from no more than 1 trial \n",
    "#     pair is a row from a pandas.core.series.Series instance with columns,['pid_self', 'pid_other', 'tmin_self', 'tmin_other', 'tmax_self', 'tmax_other', 'tmin', 'tmax', 'duration', 'event_id_int']\n",
    "    \n",
    "#     Example Usage:\n",
    "#     pair=pd.Series(df_pairs.head(1).to_pandas())\n",
    "#     event_id_int=int(pair[trial_col])#.values.get())\n",
    "#     dff=df[df[trial_col]==event_id_int]\n",
    "#     self_values,other_values=extract_xy_values_of_pair(df=dff,pair=pair,t_col=t_col)\n",
    "#     '''\n",
    "#     dff=df\n",
    "#     #DONE: optimize data retrieval from pair by using only one gpu-to-cpu memory transfer\n",
    "#     pid_self =int(pair['pid_self'])#.values.get())\n",
    "#     pid_other=int(pair['pid_other'])#.values.get())\n",
    "#     tmin     =float(pair['tmin'])#.values.get())\n",
    "#     tmax     =float(pair['tmax'])#.values.get())\n",
    "#     #failed to broadcase in cudf\n",
    "#     #     if event_id_int is not None:\n",
    "#     #         dff=df[df[trial_col]==event_id_int]\n",
    "#     #     else:\n",
    "#     #         dff=df\n",
    "#     df_self =dff.loc[(dff[pid_col]==pid_self),[t_col,'x','y']]\n",
    "#     df_other=dff.loc[(dff[pid_col]==pid_other),[t_col,'x','y']]\n",
    "#     self_values=df_self.loc[(df_self[t_col]>=tmin)&(df_self[t_col]<=tmax),['x','y']].values\n",
    "#     other_values=df_other.loc[(df_other[t_col]>=tmin)&(df_other[t_col]<=tmax),['x','y']].values\n",
    "#     return self_values,other_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec1156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T07:26:23.942805Z",
     "start_time": "2021-10-02T07:26:23.890263Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb12543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.815815Z",
     "start_time": "2021-10-02T21:31:18.796736Z"
    }
   },
   "outputs": [],
   "source": [
    "# pair=df_pairs.head(1)\n",
    "# event_id_int=int(pair[trial_col].values.get())\n",
    "# dff=df[df[trial_col]==event_id_int]\n",
    "# self_values,other_values=extract_xy_values_of_pair(df=dff,pair=pair,t_col=t_col)\n",
    "# print((self_values.shape,other_values.shape))\n",
    "# assert ( self_values.shape==other_values.shape ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0653c8e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.841465Z",
     "start_time": "2021-10-02T21:31:18.819386Z"
    }
   },
   "outputs": [],
   "source": [
    "#this function may be slow and might not even work...\n",
    "# def distance_L2_pbc_cu(self_values,other_values,shape):\n",
    "#     '''distance_L2_pbc_cu is a jit compiled function that \n",
    "#     returns for the euclidean (L2) distance between \n",
    "#     point_1 and point_2, which are in an N-cube of shape shape \n",
    "#     with periodic boundary conditions\n",
    "    \n",
    "#     Example Usage:\n",
    "#     shape=(width,height)\n",
    "#     dist_values=distance_L2_pbc_cu(self_values,other_values,shape)\n",
    "#     '''\n",
    "#     sqdiff_values = (self_values-other_values)**2\n",
    "#     #compute the other pbc options for sqdiff_values for each column\n",
    "#     for n,w in enumerate(shape):\n",
    "#         self_w_values  = self_values[:,n]\n",
    "#         other_w_values = other_values[:,n]\n",
    "#         sqdiff_w_values= sqdiff_values[:,n]\n",
    "#         sqdiff_wp_values=(self_w_values-other_w_values-w)**2\n",
    "#         sqdiff_wm_values=(self_w_values-other_w_values+w)**2\n",
    "#         boop=sqdiff_wp_values<sqdiff_w_values\n",
    "#         boom=sqdiff_wm_values<sqdiff_w_values\n",
    "#         sqdiff_values[boop,n]=sqdiff_wp_values[boop]\n",
    "#         sqdiff_values[boom,n]=sqdiff_wm_values[boom]\n",
    "\n",
    "#     dist_values=cp.sqrt(cp.sum(sqdiff_values,axis=1))\n",
    "#     return dist_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27432dfe",
   "metadata": {},
   "source": [
    "# define module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c0680e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.862601Z",
     "start_time": "2021-10-02T21:31:18.842637Z"
    }
   },
   "outputs": [],
   "source": [
    "def comp_xy_distance_L2_pbc_cu(d,width,height):\n",
    "    '''comp_xy_distance_L2_pbc_cu is a pure cudf function that \n",
    "    returns for the euclidean (L2) distance between \n",
    "    point_1 and point_2, which are in a rectangular domain of shape (width,height) \n",
    "    with periodic boundary conditions.\n",
    "    returns d with many fields added. the distance is dist.\n",
    "    supposes each row is uniquely indexed.\n",
    "    \n",
    "    Example Usage:\n",
    "    df_traj=comp_xy_distance_L2_pbc_cu(df_traj,width,height)\n",
    "    '''\n",
    "    #compute the three options for the square distance with pbc\n",
    "    d['sdx']=(d['x']-d['x_other'])**2\n",
    "    d['sdxp']=(d['x']-d['x_other']+width)**2\n",
    "    d['sdxm']=(d['x']-d['x_other']-width)**2\n",
    "    d['sdy']=(d['y']-d['y_other'])**2\n",
    "    d['sdyp']=(d['y']-d['y_other']+height)**2\n",
    "    d['sdym']=(d['y']-d['y_other']-height)**2\n",
    "    #choose the minimum of each class of option\n",
    "    d['minsdx']=d[['sdx','sdxp','sdxm']].min(axis=1)\n",
    "    d['minsdy']=d[['sdy','sdyp','sdym']].min(axis=1)\n",
    "    d['dist']=(d['minsdx'] + d['minsdy'])**0.5\n",
    "    d['R']=d['dist']\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa93ba",
   "metadata": {},
   "source": [
    "# TODO: compute dRdt versus 1/R for unconstrained random samples from smoothed and validated trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964089db",
   "metadata": {},
   "source": [
    "__Note:__ cugraph is a great tool for complex problems that happen in terms of graphs that benefit from visualization.  My graph problem is low-level, and therefore it does not appear beneficial for me to use cugraph here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8de32a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:18.882069Z",
     "start_time": "2021-10-02T21:31:18.863584Z"
    }
   },
   "outputs": [],
   "source": [
    "#define parameters\n",
    "trial_col='event_id_int'\n",
    "pid_col='particle' \n",
    "t_col='t' \n",
    "width=200\n",
    "height=200\n",
    "tmin=100.\n",
    "printing=True\n",
    "tavg1=4\n",
    "#new parameters specific to radial time series filtration\n",
    "tavg2=0.\n",
    "minimum_duration_threshold=tavg2\n",
    "minimum_duration_threshold=25 #ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c46bd2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.132720Z",
     "start_time": "2021-10-02T21:31:18.883091Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 2 files into shared memory...\n",
      "DT=0.5 ms\n"
     ]
    }
   ],
   "source": [
    "#TODO: figure out why I'm getting pid_self==pid_other in the R versus time plot...\n",
    "#recall a couple postprocessed single trials\n",
    "input_fn=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.5/smoothed_trajectories_navg_8/ic002.11_traj_sr_600_mem_0_smoothed.csv\"\n",
    "input_fn2=f\"/home/timothytyree/Documents/GitHub/care/notebooks/Data/initial-conditions-suite-3-LR/param_qu_tmax_30_Ko_5.4_diffCoef_0.0005_dt_0.5/smoothed_trajectories_navg_8/ic002.12_traj_sr_600_mem_0_smoothed.csv\"\n",
    "input_fn_lst=[input_fn,input_fn2]\n",
    "# input_fn_lst=get_all_files_matching_pattern(input_fn,trgt='.csv')\n",
    "print(f\"loading {len(input_fn_lst)} files into shared memory...\")\n",
    "df=dask_cudf.read_csv(input_fn_lst).compute()\n",
    "# df=cudf.read_csv(input_fn)\n",
    "df=df.sort_values([trial_col,pid_col, t_col], ascending=True).copy()\n",
    "DT=get_DT_cu(df,t_col,pid_col)\n",
    "navg2=int(tavg2/DT)\n",
    "if printing:\n",
    "    print(f\"DT={DT} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2424abca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.176914Z",
     "start_time": "2021-10-02T21:31:20.133911Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute the intermediate dataframe of particle start/end times\n",
    "grouped=df.groupby([trial_col,pid_col])\n",
    "dft=grouped[t_col]\n",
    "dfu=cudf.DataFrame({\n",
    "    'tmin':dft.min(),\n",
    "    'tmax':dft.max(),\n",
    "})\n",
    "dfu.reset_index(inplace=True)\n",
    "# dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70c7c6d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.198406Z",
     "start_time": "2021-10-02T21:31:20.178180Z"
    }
   },
   "outputs": [],
   "source": [
    "# trial_values=dfu[trial_col].drop_duplicates().values.get()\n",
    "# index_pair_values_lst=[]\n",
    "# for trial in trial_values:\n",
    "#     index_values=dfu[dfu[trial_col]==trial].index.values.get()\n",
    "#     index_pair_values_lst.append(cp.array(list(itertools.combinations(index_values, 2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e4e8f01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.219786Z",
     "start_time": "2021-10-02T21:31:20.199765Z"
    }
   },
   "outputs": [],
   "source": [
    "# index_pair_values=cp.concatenate(index_pair_values_lst,axis=0)\n",
    "\n",
    "# index_pair_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5082409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.240984Z",
     "start_time": "2021-10-02T21:31:20.220955Z"
    }
   },
   "outputs": [],
   "source": [
    "# index_values.shape,dfu.index.drop_duplicates().values.get().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdba781a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.426697Z",
     "start_time": "2021-10-02T21:31:20.242086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 1 cores to identify pairs of particles that coexist over 2 independent trials...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dfu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30420/3019952792.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_intersecting_pairs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midentify_all_coexisting_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpid_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpid_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrial_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_intersecting_pairs_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/care/notebooks/lib/rapids_func/routines/identify_all_coexisting_trajectory_pairs.py\u001b[0m in \u001b[0;36midentify_all_coexisting_pairs\u001b[0;34m(df, pid_col, t_col, trial_col, npartitions, use_dask, printing, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent_id_int\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent_id_int_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mdfff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mevent_id_int\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdf_intersecting_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomp_intersecting_pairs_cu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpid_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpid_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;31m#augment df_intersecting_pairs with any columns desired\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdf_intersecting_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_id_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/care/notebooks/lib/rapids_func/utils/intersecting_pairs_cu.py\u001b[0m in \u001b[0;36mcomp_intersecting_pairs_cu\u001b[0;34m(df, pid_col, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdfff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#itertools appears to need to be run on cpu only this is the main time sink...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrial_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mindex_pair_values_lst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#iterate over the trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfu' is not defined"
     ]
    }
   ],
   "source": [
    "df_intersecting_pairs_all=identify_all_coexisting_pairs(df=dfu.copy(),pid_col=pid_col,t_col=t_col,trial_col=trial_col)\n",
    "df_intersecting_pairs_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7d89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.533372Z",
     "start_time": "2021-10-02T21:31:20.533357Z"
    }
   },
   "outputs": [],
   "source": [
    "#test that duration is strictly positive\n",
    "assert ( (df_intersecting_pairs_all['duration']>0).all() )\n",
    "if printing:\n",
    "    print (f\"verified that the duration is strictly positive for all pairs of tips that coexist nontrivially\")\n",
    "\n",
    "#plot histogram of durations\n",
    "fontsize=20\n",
    "fig,ax=plt.subplots(figsize=(7,4))\n",
    "yv=np.linspace(0,0.02,10)\n",
    "ax.plot(minimum_duration_threshold+0.*yv,yv,'gray',lw=2, linestyle='dashed', label='threshold')\n",
    "trial_col_lst=sorted(df_intersecting_pairs_all[trial_col].drop_duplicates().values.get())\n",
    "for trial in trial_col_lst[:5]:\n",
    "    df_intersecting_pairs_all.query(f\"{trial_col} == {trial}\")['duration'].to_pandas().hist(density=True,bins=50,ax=ax,label=trial,grid=False)#,color='event_id_int')\n",
    "format_plot(ax, xlabel='duration of pair coexistance (ms)', ylabel='probability density', fontsize=fontsize, use_loglog=False)\n",
    "\n",
    "ax.legend(fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4396b6a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.534313Z",
     "start_time": "2021-10-02T21:31:20.534301Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONE: histograms sanity check df_intersecting_pairs\n",
    "#DONE: verify that routine gives different values for different event_id_int\n",
    "#DONE: wrap generation of df_intersecting_pairs into a function \n",
    "#DONE: include event_id_int outside ^that function\n",
    "#DONE: accumulate df_intersecting_pairs_all over all event_id_int_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b8ad9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.535578Z",
     "start_time": "2021-10-02T21:31:20.535567Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONE: verify that no pair points to the same spiral tip twice\n",
    "assert ( not (df_intersecting_pairs_all['pid_self']==df_intersecting_pairs_all['pid_other']).any() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba026a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:19:03.196565Z",
     "start_time": "2021-10-02T21:19:03.104705Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a942ec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.536442Z",
     "start_time": "2021-10-02T21:31:20.536431Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped=df.groupby([trial_col,pid_col])\n",
    "dft=grouped[t_col]\n",
    "dfu=cudf.DataFrame({\n",
    "    'tmin':dft.min(),\n",
    "    'tmax':dft.max(),\n",
    "})\n",
    "dfu.reset_index(inplace=True)\n",
    "\n",
    "df_intersecting_pairs_all=identify_all_coexisting_pairs(df=dfu.copy(),pid_col=pid_col,t_col=t_col,trial_col=trial_col)\n",
    "\n",
    "#filter by duration_threshold\n",
    "use_duration_threshold=True\n",
    "if use_duration_threshold:\n",
    "    df_pairs=df_intersecting_pairs_all[df_intersecting_pairs_all['duration']>minimum_duration_threshold]\n",
    "else:\n",
    "    df_pairs=df_intersecting_pairs_all\n",
    "#and sort\n",
    "df_pairs=df_pairs.sort_values([trial_col,'pid_self'], ascending=True).copy()\n",
    "trial_values=df[trial_col].drop_duplicates().values\n",
    "df_traj_lst=[]\n",
    "for trial in trial_values.get():\n",
    "    df_traj_lst.append(extract_xy_trajectory_pairs_cu(df,df_pairs,pid_col=pid_col,t_col=t_col))\n",
    "df_traj=cudf.concat(df_traj_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77866ce1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.537716Z",
     "start_time": "2021-10-02T21:31:20.537696Z"
    }
   },
   "outputs": [],
   "source": [
    "# from lib.rapids_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7719e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.538955Z",
     "start_time": "2021-10-02T21:31:20.538941Z"
    }
   },
   "outputs": [],
   "source": [
    "df_traj=extract_all_trajectory_pairs_cu(df,df_pairs,pid_col=pid_col,t_col=t_col, trial_col=trial_col)\n",
    "df_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9faf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.539770Z",
     "start_time": "2021-10-02T21:31:20.539757Z"
    }
   },
   "outputs": [],
   "source": [
    "ds=5. #cm for the whole domain\n",
    "DS=ds/width #cm per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6a675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.541043Z",
     "start_time": "2021-10-02T21:31:20.541028Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute the naive finite difference radial velocity between all pairs of particles\n",
    "df_traj=comp_xy_distance_L2_pbc_cu(df_traj,width,height)\n",
    "df_traj['R']=df_traj['dist']*DS #cm\n",
    "#isolate only the columns relevant to computing the attraction coefficient, a\n",
    "df_R=df_traj[[trial_col,'pid_self','pid_other',t_col,'R']].dropna()\n",
    "df_R=df_R.sort_values([trial_col,'pid_self','pid_other',t_col], ascending=True).copy()\n",
    "\n",
    "grouped=df_R.groupby([trial_col,'pid_self','pid_other'])\n",
    "dfr=grouped.rolling(2).mean()\n",
    "#compute the difference between two successive R values for each group\n",
    "df_R['incol']=df_R['R']\n",
    "mdwargs={'win_size':2}\n",
    "result = grouped.apply_grouped(rolling_diff,\n",
    "                               incols=['incol'],\n",
    "                               outcols=dict(outcol=np.float64), kwargs=\n",
    "                           mdwargs)\n",
    "df_R['dRdt']=result['outcol']/DT*1000 #cm/s\n",
    "df_R.drop(columns=['incol'],inplace=True)\n",
    "#compute the average between two successive R values for each group\n",
    "df_R['incol']=df_R['R']\n",
    "mawargs={'win_size':2}\n",
    "result = grouped.apply_grouped(rolling_avg,\n",
    "                               incols=['incol'],\n",
    "                               outcols=dict(outcol=np.float64), kwargs=\n",
    "                           mawargs)\n",
    "df_R['R_midpoint']=result['outcol'] #cm\n",
    "df_R['one_over_R']=1./df_R['R_midpoint'] #1/cm\n",
    "df_R.drop(columns=['incol'],inplace=True)\n",
    "df_R.dropna(inplace=True)\n",
    "df_R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eceb102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.541965Z",
     "start_time": "2021-10-02T21:31:20.541955Z"
    }
   },
   "outputs": [],
   "source": [
    "#DONE: compute 1/R and dRdt_naive\n",
    "#TODO: extract xy values for all particles lumped together\n",
    "# R_values=df_R['R'].values\n",
    "R_values=df_R['R_midpoint'].values\n",
    "x_values=df_R['one_over_R'].values\n",
    "y_values=df_R['dRdt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f3581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.542842Z",
     "start_time": "2021-10-02T21:31:20.542788Z"
    }
   },
   "outputs": [],
   "source": [
    "#decide on radial thresholds\n",
    "minimum_range_threshold=0.1 #cm\n",
    "maximum_range_threshold=1. #cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdadd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.544283Z",
     "start_time": "2021-10-02T21:31:20.544245Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot histogram of durations\n",
    "fontsize=20\n",
    "fig,ax=plt.subplots(figsize=(7,4))\n",
    "\n",
    "trial_col_lst=sorted(df_R[trial_col].drop_duplicates().values.get())\n",
    "for trial in trial_col_lst[:5]:\n",
    "    df_R.query(f\"{trial_col} == {trial}\")['R_midpoint'].to_pandas().hist(density=True,bins=50,ax=ax,label=trial,grid=False)#,color='event_id_int')\n",
    "        \n",
    "format_plot(ax, xlabel='distance between pair (cm)', ylabel='probability density', fontsize=fontsize, use_loglog=False)\n",
    "ax.legend(fontsize=fontsize-2)\n",
    "\n",
    "#plot threshold lines\n",
    "yv=np.linspace(0,0.6,10)\n",
    "ax.plot(minimum_range_threshold+0.*yv,yv,'gray',lw=2, linestyle='dashed', label='threshold')\n",
    "ax.plot(maximum_range_threshold+0.*yv,yv,'gray',lw=2, linestyle='dashed', label='threshold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbb828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.545466Z",
     "start_time": "2021-10-02T21:31:20.545455Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot histogram of durations\n",
    "fontsize=20\n",
    "fig,ax=plt.subplots(figsize=(7,4))\n",
    "\n",
    "trial_col_lst=sorted(df_R[trial_col].drop_duplicates().values.get())\n",
    "for trial in trial_col_lst[:5]:\n",
    "    df_R.query(f\"{trial_col} == {trial}\")['dRdt'].to_pandas().hist(density=True,bins=50,ax=ax,label=trial,grid=False)#,color='event_id_int')\n",
    "        \n",
    "format_plot(ax, xlabel='radial velocity between pair (cm)', ylabel='probability density', fontsize=fontsize, use_loglog=False)\n",
    "ax.legend(fontsize=fontsize-2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e2a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.547175Z",
     "start_time": "2021-10-02T21:31:20.547163Z"
    }
   },
   "outputs": [],
   "source": [
    "#index by individual pairs\n",
    "dfr=df_R.set_index([trial_col,'pid_self','pid_other']).sort_values(by='t')\n",
    "dfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773c1c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.548086Z",
     "start_time": "2021-10-02T21:31:20.548071Z"
    }
   },
   "outputs": [],
   "source": [
    "#identify all pairs that are within this range\n",
    "boo=(dfr['R']<=maximum_range_threshold)&(dfr['R']>=minimum_range_threshold)\n",
    "# index_values=dfr.index.drop_duplicates().values\n",
    "index_values=boo.index.drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbb869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.549408Z",
     "start_time": "2021-10-02T21:31:20.549391Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#plot a few particle events\n",
    "fontsize=14\n",
    "fig,ax=plt.subplots(figsize=(7,4))\n",
    "for iv in index_values.get()[:3]:\n",
    "    x_values,y_values=dfr.loc[iv][['t','R']].sort_values(by='t').values.T.get()\n",
    "    ax.plot(x_values-x_values[0],y_values,label=f\"pair {(iv[1],iv[2])}\")\n",
    "format_plot(ax, xlabel=r'$t$ (ms)', ylabel=r'$R$ (cm)', fontsize=fontsize, use_loglog=False)\n",
    "ax.legend(fontsize=fontsize-2)\n",
    "plt.title(f'tavg1={tavg1} ms, tavg1={tavg1} ms\\n')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b08cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:17:36.407805Z",
     "start_time": "2021-10-02T21:17:36.375071Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca4070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.550803Z",
     "start_time": "2021-10-02T21:31:20.550791Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot a few particle events\n",
    "fontsize=14\n",
    "fig,ax=plt.subplots(figsize=(7,4))\n",
    "for iv in index_values.get()[:2]:\n",
    "    x_values,y_values=dfr.loc[iv][['R_midpoint','dRdt']].values.T.get()\n",
    "#     ax.scatter(x_values,y_values,label=f\"pair {(iv[1],iv[2])}\")\n",
    "    ax.plot(x_values,y_values,label=f\"pair {(iv[1],iv[2])}\")\n",
    "format_plot(ax, xlabel=r'$R$ (cm)', ylabel=r'$dR/dt$ (cm/s)', fontsize=fontsize, use_loglog=False)\n",
    "ax.legend(fontsize=fontsize-2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443def2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.551865Z",
     "start_time": "2021-10-02T21:31:20.551849Z"
    }
   },
   "outputs": [],
   "source": [
    "#particles have been allowed to pair with themselves at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e577f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.553320Z",
     "start_time": "2021-10-02T21:31:20.553306Z"
    }
   },
   "outputs": [],
   "source": [
    "itertools.combinations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c66ca54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51afe54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T20:07:55.210863Z",
     "start_time": "2021-10-02T20:07:55.018946Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d81aa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.554217Z",
     "start_time": "2021-10-02T21:31:20.554206Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped.apply_grouped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63e040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.555085Z",
     "start_time": "2021-10-02T21:31:20.555074Z"
    }
   },
   "outputs": [],
   "source": [
    "# grouped.shift(1)[t_col]-grouped[t_col]\n",
    "grouped.apply_grouped(diff_cu,incol='t',outcol='dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526477d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33aaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36e84a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.555980Z",
     "start_time": "2021-10-02T21:31:20.555968Z"
    }
   },
   "outputs": [],
   "source": [
    "# #THIS IS THE SHORTEST PATH TO Success\n",
    "# MULTIINDEX SO THE PRIMITIVE OBJECT IS THE RANGE TIME SERIES\n",
    "# COMPUTE KEY VALUES 1/R AND DRDT\n",
    "# NAIVELY MEASURE A\n",
    "# REMOVE OUTLIER A VALUES OR A THAT RECIEVED A NASTY FIT\n",
    "# RECOMPUTE A WITH AN ENSEMBLE BOOTSTRAP\n",
    "# IF A IS STILL NOT GREAT, CONSIDER USINVE TAVG2 WITH SOMETHING LIKE A SAVGOL FILTER IMPLEMENTED AS AN FIR FILTER\n",
    "# KEEP TRYING UNTIL I HAVE AN ESTIMATE OF A THAT IS CONSISTENT WITH THE PARTICLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53786d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e398e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.557556Z",
     "start_time": "2021-10-02T21:31:20.557542Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # dmis.to_pandas().index\n",
    "# # dmis.to_pandas().index.values.T\n",
    "# # dmis.to_pandas().index.values.T.shape\n",
    "\n",
    "# # targ_index=dmis.to_pandas().index.values\n",
    "# # # .set_dtype(int)\n",
    "\n",
    "\n",
    "\n",
    "# # dmis.to_pandas().index.values.T.shape,dfmi.to_pandas().shape\n",
    "\n",
    "\n",
    "# # dfmi.to_pandas().loc[tuple(targ_index)]\n",
    "# # # dfmi.to_pandas().iloc[[0,0],'x']\n",
    "\n",
    "\n",
    "# # grouped.get_group\n",
    "\n",
    "# #doesn't work for cudf yet...\n",
    "# # import functools\n",
    "# # S = pd.Series([i / 100.0 for i in range(1, 11)])\n",
    "# # def cum_ret(x, y):\n",
    "# #     return x * (1 + y)\n",
    "# # def red(x):\n",
    "# #     return functools.reduce(cum_ret, x, 1.0)\n",
    "# # S.expanding().apply(red, raw=True)\n",
    "\n",
    "# # df_pairs[trial_col].drop_duplicates().values.get()\n",
    "# # MAKE A LIST OF INDICIES WHERE PID_COL IS REPEATED MULTIPLICITY TIMES\n",
    "# # multiplicity_self(level=1)\n",
    "# mi=multiplicity_self.index\n",
    "# pid_self_values=mi.get_level_values(1).values\n",
    "# multiplicity_self_values=multiplicity_self.values\n",
    "# # pid_self_values.shape,multiplicity_self_values.shape\n",
    "# target_pid_index_values=cp.repeat(pid_self_values,tuple(multiplicity_self_values.get()))\n",
    "# print(target_pid_index_values.shape)\n",
    "# #TODO: for each member of pid_self_values, copy it multiplicity_self_values times\n",
    "# #WARNING: watch out for multiple event_id_int values!\n",
    "# #SOLN: use loc on df indexed with TRIAL_COL then PID_COL as dfp\n",
    "\n",
    "# # retval=cp.repeat(pid_self_values,multiplicity_self_values.get(),axis=-1)\n",
    "# # cp.broadcast_to?\n",
    "# trial_self_values=mi.get_level_values(0).values\n",
    "# multiplicity_self_values=multiplicity_self.values\n",
    "# target_trial_values=cp.repeat(trial_self_values,tuple(multiplicity_self_values.get()))\n",
    "# print(target_trial_values.shape)\n",
    "\n",
    "# dfr=cudf.DataFrame({trial_col:target_trial_values,pid_col:target_pid_index_values})\n",
    "# dfr.head()\n",
    "\n",
    "# dmi=df_pairs.groupby([trial_col,'pid_self','pid_other'])\n",
    "# dmi.count()\n",
    "\n",
    "# # type(dmi.collect())\n",
    "\n",
    "# df.groupby([pid_col])\n",
    "\n",
    "# dfc=df.groupby([trial_col,pid_col]).collect()\n",
    "# dfc.head()\n",
    "\n",
    "# retval=df.set_index([trial_col,pid_col])#.loc[trial_self_values]#,pid_self_values]]\n",
    "# retval=df.set_index([trial_col,pid_col])[[list(trial_self_values.get()),list(pid_self_values.get())]]\n",
    "# retval\n",
    "\n",
    "# all_t_values=df[t_col].drop_duplicates().values\n",
    "\n",
    "# #TODO: make the largest possible multiindexed array that contains the target\n",
    "# cudf.DataFrame([target_trial_values,target_pid_index_values])\n",
    "\n",
    "# cudf.MultiIndex.f\n",
    "\n",
    "# multiplicity_self_values.get()\n",
    "\n",
    "# df.loc[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe85d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.558465Z",
     "start_time": "2021-10-02T21:31:20.558453Z"
    }
   },
   "outputs": [],
   "source": [
    "# #THIS IS THE SHORTEST PATH TO Success\n",
    "# df.loc[[0,0]]\n",
    "# #can I repeat a label? using loc. yes!  THIS CAN BE SOLVE SIMPLY BY \n",
    "# # USE DF_PAIRS TO DETERMINE THE MULTIPLICITY_self OF EACH PID_SELF\n",
    "# multiplicity_self=df_pairs.groupby([trial_col,'pid_self'])['tmin'].count()\n",
    "# # # USE DF_PAIRS TO DETERMINE THE MULTIPLICITY_other OF EACH PID_OTHER\n",
    "# # SET THE INDEX TO PID_COL IN DF AS DFP\n",
    "# dfp=df.set_index(pid_col)\n",
    "# # MAKE A LIST OF INDICIES WHERE PID_COL IS REPEATED MULTIPLICITY TIMES\n",
    "\n",
    "# # LOCATE AND COPY DF WITH ^THAT LIST FOR SELF\n",
    "# # MAKE A LIST OF INDICIES WHERE PID_COL IS REPEATED MULTIPLICITY TIMES\n",
    "# # LOCATE AND COPY DF WITH ^THAT LIST FOR OTHER\n",
    "# # MAKE A SINGLE DF WITH ALL OF THE DESIRED COLUMNS (SEE HANDWRITTEN (3))\n",
    "# # REWRITE A PANDASESQUE DIST_L2_PBC_CUDF MEASURE \n",
    "# # COMPUTE THE CUDF DATAFRAME OF ALL RANGE TIMESERIES FOR ALL PAIRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5293b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.559294Z",
     "start_time": "2021-10-02T21:31:20.559282Z"
    }
   },
   "outputs": [],
   "source": [
    "# targ_index_col_lst=[trial_col,'pid_self','pid_other',t_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd0518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ead681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b4ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.560331Z",
     "start_time": "2021-10-02T21:31:20.560318Z"
    }
   },
   "outputs": [],
   "source": [
    "# #DONE: visually verify these values look sensible\n",
    "# plt.plot(dist_values.get())\n",
    "# plt.show()\n",
    "# plt.plot(self_values[:,0].get(),self_values[:,1].get())\n",
    "# plt.plot(other_values[:,0].get(),other_values[:,1].get())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065ec9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.561259Z",
     "start_time": "2021-10-02T21:31:20.561248Z"
    }
   },
   "outputs": [],
   "source": [
    "#is there a datum missing somewhere in the bulk?  No. removing the first self resolved the problem\n",
    "#maybe I'm picking up an extra value from the other event_id?\n",
    "# dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2246e5c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T07:38:59.006840Z",
     "start_time": "2021-10-02T07:38:58.967567Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d6d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16e077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c7a89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.562073Z",
     "start_time": "2021-10-02T21:31:20.562061Z"
    }
   },
   "outputs": [],
   "source": [
    "# def comp_xy_distance_pbc_cu(self_values,other_values,width,height):\n",
    "#     pass\n",
    "# #TODO:compute the distance in x between any points where two spiral tips occur at the same time in t\n",
    "# #is the best way to do this to project to cupy and to run all rows in  together in a daskbag?  sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c2381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.562865Z",
     "start_time": "2021-10-02T21:31:20.562852Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO(IMMEDIATE FOLLOWUP GOAL): show how insensitive a is to choice in navg1 (and/or navg2 if I'm using it!)\n",
    "#GOAL_QUESTION: does there exist a tavg1 that produces the right expected a for a single termination event??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785a01e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T21:31:20.563918Z",
     "start_time": "2021-10-02T21:31:20.563906Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: estimate an ensemble averaged a estimate\n",
    "#TODO: augment df_interacting_pairs with estimates for a for individual pairs of particles\n",
    "#TODO: use ^that to filter based on Rsq or Delta_a and recompute an ensemble averaged a estimate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
